{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea89806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Na√Øve Bayes\n",
      "==================================================\n",
      "Best Parameters:  {}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.5278969957081545\n",
      "Precision: 0.5636363636363636\n",
      "Recall: 0.26495726495726496\n",
      "F1 Score: 0.36046511627906974\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.51931330472103\n",
      "Precision: 0.5111111111111111\n",
      "Recall: 0.9829059829059829\n",
      "F1 Score: 0.672514619883041\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.51931330472103\n",
      "Precision: 0.5092592592592593\n",
      "Recall: 0.9482758620689655\n",
      "F1 Score: 0.6626506024096386\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.48497854077253216\n",
      "Precision: 0.4898989898989899\n",
      "Recall: 0.8362068965517241\n",
      "F1 Score: 0.6178343949044586\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.5129310344827587\n",
      "Precision: 0.5066666666666667\n",
      "Recall: 0.9827586206896551\n",
      "F1 Score: 0.6686217008797654\n",
      "\n",
      "Average Accuracy: 0.512886636081101\n",
      "Average Precision: 0.5161144781144781\n",
      "Average Recall: 0.8030209254347185\n",
      "Average F1 Score: 0.5964172868711947\n",
      "\n",
      "Model: SVM\n",
      "==================================================\n",
      "Best Parameters:  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8497854077253219\n",
      "Precision: 0.7697368421052632\n",
      "Recall: 1.0\n",
      "F1 Score: 0.8698884758364313\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8841201716738197\n",
      "Precision: 0.8125\n",
      "Recall: 1.0\n",
      "F1 Score: 0.896551724137931\n",
      "\n",
      "Average Accuracy: 0.866952789699571\n",
      "Average Precision: 0.7911184210526319\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.8832200999871809\n",
      "\n",
      "Model: Logistic Regression\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.64685511        nan 0.64513098        nan 0.6528748 ]\n",
      "  warnings.warn(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.648068669527897\n",
      "Precision: 0.6422764227642277\n",
      "Recall: 0.6752136752136753\n",
      "F1 Score: 0.6583333333333333\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.7553648068669528\n",
      "Precision: 0.7941176470588235\n",
      "Recall: 0.6923076923076923\n",
      "F1 Score: 0.7397260273972602\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.7510729613733905\n",
      "Precision: 0.8085106382978723\n",
      "Recall: 0.6551724137931034\n",
      "F1 Score: 0.7238095238095238\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.5107296137339056\n",
      "Precision: 0.5142857142857142\n",
      "Recall: 0.3103448275862069\n",
      "F1 Score: 0.3870967741935484\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.5991379310344828\n",
      "Precision: 0.6493506493506493\n",
      "Recall: 0.43103448275862066\n",
      "F1 Score: 0.5181347150259067\n",
      "\n",
      "Average Accuracy: 0.6528747965073257\n",
      "Average Precision: 0.6817082143514575\n",
      "Average Recall: 0.5528146183318597\n",
      "Average F1 Score: 0.6054200747519145\n",
      "\n",
      "Model: Random Forest\n",
      "==================================================\n",
      "Best Parameters:  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8927038626609443\n",
      "Precision: 0.8432835820895522\n",
      "Recall: 0.9658119658119658\n",
      "F1 Score: 0.900398406374502\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8884120171673819\n",
      "Precision: 0.8823529411764706\n",
      "Recall: 0.8974358974358975\n",
      "F1 Score: 0.8898305084745762\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.9313304721030042\n",
      "Precision: 0.9464285714285714\n",
      "Recall: 0.9137931034482759\n",
      "F1 Score: 0.9298245614035088\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.7811158798283262\n",
      "Precision: 0.9113924050632911\n",
      "Recall: 0.6206896551724138\n",
      "F1 Score: 0.7384615384615385\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.853448275862069\n",
      "Precision: 0.9880952380952381\n",
      "Recall: 0.7155172413793104\n",
      "F1 Score: 0.83\n",
      "\n",
      "Average Accuracy: 0.869402101524345\n",
      "Average Precision: 0.9143105475706246\n",
      "Average Recall: 0.8226495726495726\n",
      "Average F1 Score: 0.8577030029428251\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': ['Na√Øve Bayes', 'SVM', 'Logistic Regression', 'Random Forest'],\n",
       " 'Best Parameters': [{},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'penalty': 'l2'},\n",
       "  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}],\n",
       " 'Average Accuracy': [0.512886636081101,\n",
       "  0.866952789699571,\n",
       "  0.6528747965073257,\n",
       "  0.869402101524345],\n",
       " 'Average Precision': [0.5161144781144781,\n",
       "  0.7911184210526319,\n",
       "  0.6817082143514575,\n",
       "  0.9143105475706246],\n",
       " 'Average Recall': [0.8030209254347185,\n",
       "  1.0,\n",
       "  0.5528146183318597,\n",
       "  0.8226495726495726],\n",
       " 'Average F1 Score': [0.5964172868711947,\n",
       "  0.8832200999871809,\n",
       "  0.6054200747519145,\n",
       "  0.8577030029428251]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Read the data into a dataframe\n",
    "df = pd.read_csv('cleaned_engagement_data.csv')\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df[['total_direct_mentions', \n",
    "        'total_indirect_mentions', \n",
    "        'total_likes', \n",
    "        'total_retweets', \n",
    "        'total_project_followers', \n",
    "        'total_indirect_followers', \n",
    "        'soft_cap']]\n",
    "y = df['ico_success']\n",
    "\n",
    "# Perform Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Define the parameter grids for grid search\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "lr_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "nb_param_grid = {}\n",
    "\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Na√Øve Bayes': (GaussianNB(), nb_param_grid),\n",
    "    'SVM': (SVC(random_state=42), svm_param_grid),\n",
    "    'Logistic Regression': (LogisticRegression(random_state=42), lr_param_grid),\n",
    "    'Random Forest': (RandomForestClassifier(random_state=42), rf_param_grid),\n",
    "}\n",
    "\n",
    "result = {\n",
    "    \"Model\": [],\n",
    "    \"Best Parameters\": [],\n",
    "    \"Average Accuracy\": [],\n",
    "    \"Average Precision\": [],\n",
    "    \"Average Recall\": [],\n",
    "    \"Average F1 Score\": [],\n",
    "}\n",
    "\n",
    "# Perform grid search and cross-validation for each model\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    result[\"Model\"].append(model_name)\n",
    "\n",
    "    # Perform grid search with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # Print the best parameters and the corresponding score\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    print()\n",
    "\n",
    "    result[\"Best Parameters\"].append(grid_search.best_params_)\n",
    "\n",
    "    # Perform 5-fold cross-validation with the best model\n",
    "    cv_results = cross_validate(grid_search.best_estimator_, X_resampled, y_resampled, cv=5, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    overfitted_folds = 0  # Counter for overfitted folds\n",
    "    for fold_idx, fold_result in enumerate(cv_results['test_accuracy']):\n",
    "        if fold_result == 1.0:  # Check for overfitted fold\n",
    "            overfitted_folds += 1\n",
    "            continue  # Skip overfitted fold\n",
    "\n",
    "        print(f\"Fold {fold_idx+1}:\")\n",
    "        print(f\"Accuracy: {fold_result}\")\n",
    "        print(f\"Precision: {cv_results['test_precision'][fold_idx]}\")\n",
    "        print(f\"Recall: {cv_results['test_recall'][fold_idx]}\")\n",
    "        print(f\"F1 Score: {cv_results['test_f1'][fold_idx]}\")\n",
    "        print()\n",
    "\n",
    "    # Calculate average results across non-overfitted folds\n",
    "    num_folds = len(cv_results['test_accuracy'])\n",
    "    num_non_overfitted_folds = num_folds - overfitted_folds\n",
    "    avg_accuracy = (sum(cv_results['test_accuracy']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_precision = (sum(cv_results['test_precision']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_recall = (sum(cv_results['test_recall']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_f1 = (sum(cv_results['test_f1']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "\n",
    "    # Print the average results\n",
    "    print(f\"Average Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Average Precision: {avg_precision}\")\n",
    "    print(f\"Average Recall: {avg_recall}\")\n",
    "    print(f\"Average F1 Score: {avg_f1}\")\n",
    "    print()\n",
    "\n",
    "    result[\"Average Accuracy\"].append(avg_accuracy)\n",
    "    result[\"Average Precision\"].append(avg_precision)\n",
    "    result[\"Average Recall\"].append(avg_recall)\n",
    "    result[\"Average F1 Score\"].append(avg_f1)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a6db9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "perf_ds = Dataset.from_dict(result).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef88037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Na√Øve Bayes</td>\n",
       "      <td>{'C': None, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.512887</td>\n",
       "      <td>0.516114</td>\n",
       "      <td>0.803021</td>\n",
       "      <td>0.596417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'ma...</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.791118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 10.0, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.652875</td>\n",
       "      <td>0.681708</td>\n",
       "      <td>0.552815</td>\n",
       "      <td>0.605420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'C': None, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.869402</td>\n",
       "      <td>0.914311</td>\n",
       "      <td>0.822650</td>\n",
       "      <td>0.857703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                                    Best Parameters  \\\n",
       "0          Na√Øve Bayes  {'C': None, 'gamma': None, 'kernel': None, 'ma...   \n",
       "1                  SVM  {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'ma...   \n",
       "2  Logistic Regression  {'C': 10.0, 'gamma': None, 'kernel': None, 'ma...   \n",
       "3        Random Forest  {'C': None, 'gamma': None, 'kernel': None, 'ma...   \n",
       "\n",
       "   Average Accuracy  Average Precision  Average Recall  Average F1 Score  \n",
       "0          0.512887           0.516114        0.803021          0.596417  \n",
       "1          0.866953           0.791118        1.000000          0.883220  \n",
       "2          0.652875           0.681708        0.552815          0.605420  \n",
       "3          0.869402           0.914311        0.822650          0.857703  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91c8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = perf_ds.drop(columns=[\"Best Parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12dc6f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Na√Øve Bayes</th>\n",
       "      <td>51.288664</td>\n",
       "      <td>51.611448</td>\n",
       "      <td>80.302093</td>\n",
       "      <td>59.641729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>86.695279</td>\n",
       "      <td>79.111842</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.322010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>65.287480</td>\n",
       "      <td>68.170821</td>\n",
       "      <td>55.281462</td>\n",
       "      <td>60.542007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>86.940210</td>\n",
       "      <td>91.431055</td>\n",
       "      <td>82.264957</td>\n",
       "      <td>85.770300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Average Accuracy  Average Precision  Average Recall  \\\n",
       "Model                                                                      \n",
       "Na√Øve Bayes                 51.288664          51.611448       80.302093   \n",
       "SVM                         86.695279          79.111842      100.000000   \n",
       "Logistic Regression         65.287480          68.170821       55.281462   \n",
       "Random Forest               86.940210          91.431055       82.264957   \n",
       "\n",
       "                     Average F1 Score  \n",
       "Model                                  \n",
       "Na√Øve Bayes                 59.641729  \n",
       "SVM                         88.322010  \n",
       "Logistic Regression         60.542007  \n",
       "Random Forest               85.770300  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = res2.set_index(res2.columns[0]).mul(100)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7726b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Na√Øve Bayes</th>\n",
       "      <td>51.3%</td>\n",
       "      <td>51.6%</td>\n",
       "      <td>80.3%</td>\n",
       "      <td>59.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>86.7%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>88.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>65.3%</td>\n",
       "      <td>68.2%</td>\n",
       "      <td>55.3%</td>\n",
       "      <td>60.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>86.9%</td>\n",
       "      <td>91.4%</td>\n",
       "      <td>82.3%</td>\n",
       "      <td>85.8%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Average Accuracy Average Precision Average Recall  \\\n",
       "Model                                                                   \n",
       "Na√Øve Bayes                    51.3%             51.6%          80.3%   \n",
       "SVM                            86.7%             79.1%         100.0%   \n",
       "Logistic Regression            65.3%             68.2%          55.3%   \n",
       "Random Forest                  86.9%             91.4%          82.3%   \n",
       "\n",
       "                    Average F1 Score  \n",
       "Model                                 \n",
       "Na√Øve Bayes                    59.6%  \n",
       "SVM                            88.3%  \n",
       "Logistic Regression            60.5%  \n",
       "Random Forest                  85.8%  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in res2.select_dtypes(include=[\"number\"]).columns:\n",
    "    res2[key] = res2[key].apply(\"{:.1f}%\".format)\n",
    "\n",
    "res2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
