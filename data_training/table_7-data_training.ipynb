{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a98b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naïve Bayes\n",
      "==================================================\n",
      "Best Parameters:  {}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.45263157894736844\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.09473684210526316\n",
      "F1 Score: 0.14754098360655737\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 0.968421052631579\n",
      "F1 Score: 0.6594982078853047\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.5105263157894737\n",
      "Precision: 0.5055555555555555\n",
      "Recall: 0.9578947368421052\n",
      "F1 Score: 0.6618181818181819\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.4789473684210526\n",
      "Precision: 0.4887640449438202\n",
      "Recall: 0.9157894736842105\n",
      "F1 Score: 0.6373626373626373\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.5105263157894737\n",
      "Precision: 0.5061728395061729\n",
      "Recall: 0.8631578947368421\n",
      "F1 Score: 0.6381322957198443\n",
      "\n",
      "Average Accuracy: 0.4905263157894737\n",
      "Average Precision: 0.46676515466777635\n",
      "Average Recall: 0.76\n",
      "Average F1 Score: 0.548870461278505\n",
      "\n",
      "Model: SVM\n",
      "==================================================\n",
      "Best Parameters:  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8473684210526315\n",
      "Precision: 0.7661290322580645\n",
      "Recall: 1.0\n",
      "F1 Score: 0.867579908675799\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8894736842105263\n",
      "Precision: 0.8189655172413793\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9004739336492891\n",
      "\n",
      "Average Accuracy: 0.8684210526315788\n",
      "Average Precision: 0.792547274749722\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.884026921162544\n",
      "\n",
      "Model: Logistic Regression\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.69052632        nan 0.68631579        nan 0.68      ]\n",
      "  warnings.warn(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.1, 'penalty': 'l2'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.7\n",
      "Precision: 0.6862745098039216\n",
      "Recall: 0.7368421052631579\n",
      "F1 Score: 0.7106598984771574\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.7105263157894737\n",
      "Precision: 0.7702702702702703\n",
      "Recall: 0.6\n",
      "F1 Score: 0.6745562130177515\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.7263157894736842\n",
      "Precision: 0.7792207792207793\n",
      "Recall: 0.631578947368421\n",
      "F1 Score: 0.6976744186046512\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.6368421052631579\n",
      "Precision: 0.703125\n",
      "Recall: 0.47368421052631576\n",
      "F1 Score: 0.5660377358490566\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.6789473684210526\n",
      "Precision: 0.7575757575757576\n",
      "Recall: 0.5263157894736842\n",
      "F1 Score: 0.6211180124223602\n",
      "\n",
      "Average Accuracy: 0.6905263157894737\n",
      "Average Precision: 0.7392932633741458\n",
      "Average Recall: 0.5936842105263158\n",
      "Average F1 Score: 0.6540092556741953\n",
      "\n",
      "Model: Random Forest\n",
      "==================================================\n",
      "Best Parameters:  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8368421052631579\n",
      "Precision: 0.8076923076923077\n",
      "Recall: 0.8842105263157894\n",
      "F1 Score: 0.8442211055276382\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8578947368421053\n",
      "Precision: 0.8953488372093024\n",
      "Recall: 0.8105263157894737\n",
      "F1 Score: 0.850828729281768\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.9210526315789473\n",
      "Precision: 1.0\n",
      "Recall: 0.8421052631578947\n",
      "F1 Score: 0.9142857142857143\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.9368421052631579\n",
      "Precision: 0.9770114942528736\n",
      "Recall: 0.8947368421052632\n",
      "F1 Score: 0.9340659340659341\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.9368421052631579\n",
      "Precision: 1.0\n",
      "Recall: 0.8736842105263158\n",
      "F1 Score: 0.9325842696629213\n",
      "\n",
      "Average Accuracy: 0.8978947368421052\n",
      "Average Precision: 0.9360105278308968\n",
      "Average Recall: 0.8610526315789475\n",
      "Average F1 Score: 0.8951971505647952\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': ['Naïve Bayes', 'SVM', 'Logistic Regression', 'Random Forest'],\n",
       " 'Best Parameters': [{},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'penalty': 'l2'},\n",
       "  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}],\n",
       " 'Average Accuracy': [0.4905263157894737,\n",
       "  0.8684210526315788,\n",
       "  0.6905263157894737,\n",
       "  0.8978947368421052],\n",
       " 'Average Precision': [0.46676515466777635,\n",
       "  0.792547274749722,\n",
       "  0.7392932633741458,\n",
       "  0.9360105278308968],\n",
       " 'Average Recall': [0.76, 1.0, 0.5936842105263158, 0.8610526315789475],\n",
       " 'Average F1 Score': [0.548870461278505,\n",
       "  0.884026921162544,\n",
       "  0.6540092556741953,\n",
       "  0.8951971505647952]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data into a dataframe\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df[\n",
    "    [\n",
    "        \"total_direct_mentions\",\n",
    "        \"total_indirect_mentions\",\n",
    "        \"total_likes\",\n",
    "        \"total_retweets\",\n",
    "        \"total_project_followers\",\n",
    "        \"total_indirect_followers\",\n",
    "        \"total_positive_direct_mentions\",\n",
    "        \"total_negative_direct_mentions\",\n",
    "        \"total_positive_indirect_mentions\",\n",
    "        \"total_negative_indirect_mentions\",\n",
    "        \"soft_cap\",\n",
    "    ]\n",
    "]\n",
    "y = df[\"ico_success\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Perform Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the parameter grids for grid search\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "lr_param_grid = {\"C\": [0.1, 1, 10], \"penalty\": [\"l1\", \"l2\"]}\n",
    "\n",
    "nb_param_grid = {}\n",
    "\n",
    "svm_param_grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"gamma\": [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "}\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"Naïve Bayes\": (GaussianNB(), nb_param_grid),\n",
    "    \"SVM\": (SVC(random_state=42), svm_param_grid),\n",
    "    \"Logistic Regression\": (LogisticRegression(random_state=42), lr_param_grid),\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42), rf_param_grid),\n",
    "}\n",
    "\n",
    "result = {\n",
    "    \"Model\": [],\n",
    "    \"Best Parameters\": [],\n",
    "    \"Average Accuracy\": [],\n",
    "    \"Average Precision\": [],\n",
    "    \"Average Recall\": [],\n",
    "    \"Average F1 Score\": [],\n",
    "}\n",
    "\n",
    "best_estimators = {}\n",
    "\n",
    "# Perform grid search and cross-validation for each model\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    result[\"Model\"].append(model_name)\n",
    "\n",
    "    # Perform grid search with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model, param_grid=param_grid, cv=5, scoring=\"accuracy\"\n",
    "    )\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # Print the best parameters and the corresponding score\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    print()\n",
    "\n",
    "    result[\"Best Parameters\"].append(grid_search.best_params_)\n",
    "\n",
    "    best_estimators[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    # Perform 5-fold cross-validation with the best model\n",
    "    cv_results = cross_validate(\n",
    "        grid_search.best_estimator_,\n",
    "        X_resampled,\n",
    "        y_resampled,\n",
    "        cv=5,\n",
    "        scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    "    )\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    overfitted_folds = 0  # Counter for overfitted folds\n",
    "    for fold_idx, fold_result in enumerate(cv_results[\"test_accuracy\"]):\n",
    "        if fold_result == 1.0:  # Check for overfitted fold\n",
    "            overfitted_folds += 1\n",
    "            continue  # Skip overfitted fold\n",
    "\n",
    "        print(f\"Fold {fold_idx+1}:\")\n",
    "        print(f\"Accuracy: {fold_result}\")\n",
    "        print(f\"Precision: {cv_results['test_precision'][fold_idx]}\")\n",
    "        print(f\"Recall: {cv_results['test_recall'][fold_idx]}\")\n",
    "        print(f\"F1 Score: {cv_results['test_f1'][fold_idx]}\")\n",
    "        print()\n",
    "\n",
    "    # Calculate average results across non-overfitted folds\n",
    "    num_folds = len(cv_results[\"test_accuracy\"])\n",
    "    num_non_overfitted_folds = num_folds - overfitted_folds\n",
    "    avg_accuracy = (\n",
    "        sum(cv_results[\"test_accuracy\"]) - (overfitted_folds * 1)\n",
    "    ) / num_non_overfitted_folds\n",
    "    avg_precision = (\n",
    "        sum(cv_results[\"test_precision\"]) - (overfitted_folds * 1)\n",
    "    ) / num_non_overfitted_folds\n",
    "    avg_recall = (\n",
    "        sum(cv_results[\"test_recall\"]) - (overfitted_folds * 1)\n",
    "    ) / num_non_overfitted_folds\n",
    "    avg_f1 = (\n",
    "        sum(cv_results[\"test_f1\"]) - (overfitted_folds * 1)\n",
    "    ) / num_non_overfitted_folds\n",
    "\n",
    "    # Print the average results\n",
    "    print(f\"Average Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Average Precision: {avg_precision}\")\n",
    "    print(f\"Average Recall: {avg_recall}\")\n",
    "    print(f\"Average F1 Score: {avg_f1}\")\n",
    "    print()\n",
    "\n",
    "    result[\"Average Accuracy\"].append(avg_accuracy)\n",
    "    result[\"Average Precision\"].append(avg_precision)\n",
    "    result[\"Average Recall\"].append(avg_recall)\n",
    "    result[\"Average F1 Score\"].append(avg_f1)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9817e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "perf_ds = Dataset.from_dict(result).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a426b61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>{'C': None, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.490526</td>\n",
       "      <td>0.466765</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.548870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'ma...</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.792547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.1, 'gamma': None, 'kernel': None, 'max...</td>\n",
       "      <td>0.690526</td>\n",
       "      <td>0.739293</td>\n",
       "      <td>0.593684</td>\n",
       "      <td>0.654009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'C': None, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.897895</td>\n",
       "      <td>0.936011</td>\n",
       "      <td>0.861053</td>\n",
       "      <td>0.895197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                                    Best Parameters  \\\n",
       "0          Naïve Bayes  {'C': None, 'gamma': None, 'kernel': None, 'ma...   \n",
       "1                  SVM  {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'ma...   \n",
       "2  Logistic Regression  {'C': 0.1, 'gamma': None, 'kernel': None, 'max...   \n",
       "3        Random Forest  {'C': None, 'gamma': None, 'kernel': None, 'ma...   \n",
       "\n",
       "   Average Accuracy  Average Precision  Average Recall  Average F1 Score  \n",
       "0          0.490526           0.466765        0.760000          0.548870  \n",
       "1          0.868421           0.792547        1.000000          0.884027  \n",
       "2          0.690526           0.739293        0.593684          0.654009  \n",
       "3          0.897895           0.936011        0.861053          0.895197  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9525dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = perf_ds.drop(columns=[\"Best Parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b95ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>49.052632</td>\n",
       "      <td>46.676515</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>54.887046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>86.842105</td>\n",
       "      <td>79.254727</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.402692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>69.052632</td>\n",
       "      <td>73.929326</td>\n",
       "      <td>59.368421</td>\n",
       "      <td>65.400926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>89.789474</td>\n",
       "      <td>93.601053</td>\n",
       "      <td>86.105263</td>\n",
       "      <td>89.519715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Average Accuracy  Average Precision  Average Recall  \\\n",
       "Model                                                                      \n",
       "Naïve Bayes                 49.052632          46.676515       76.000000   \n",
       "SVM                         86.842105          79.254727      100.000000   \n",
       "Logistic Regression         69.052632          73.929326       59.368421   \n",
       "Random Forest               89.789474          93.601053       86.105263   \n",
       "\n",
       "                     Average F1 Score  \n",
       "Model                                  \n",
       "Naïve Bayes                 54.887046  \n",
       "SVM                         88.402692  \n",
       "Logistic Regression         65.400926  \n",
       "Random Forest               89.519715  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = res2.set_index(res2.columns[0]).mul(100)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f5ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>49.1%</td>\n",
       "      <td>46.7%</td>\n",
       "      <td>76.0%</td>\n",
       "      <td>54.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>86.8%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>88.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>69.1%</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>59.4%</td>\n",
       "      <td>65.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>89.8%</td>\n",
       "      <td>93.6%</td>\n",
       "      <td>86.1%</td>\n",
       "      <td>89.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Average Accuracy Average Precision Average Recall  \\\n",
       "Model                                                                   \n",
       "Naïve Bayes                    49.1%             46.7%          76.0%   \n",
       "SVM                            86.8%             79.3%         100.0%   \n",
       "Logistic Regression            69.1%             73.9%          59.4%   \n",
       "Random Forest                  89.8%             93.6%          86.1%   \n",
       "\n",
       "                    Average F1 Score  \n",
       "Model                                 \n",
       "Naïve Bayes                    54.9%  \n",
       "SVM                            88.4%  \n",
       "Logistic Regression            65.4%  \n",
       "Random Forest                  89.5%  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in res2.select_dtypes(include=[\"number\"]).columns:\n",
    "    res2[key] = res2[key].apply(\"{:.1f}%\".format)\n",
    "\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633a2f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Naïve Bayes': GaussianNB(),\n",
       " 'SVM': SVC(C=1, gamma=0.01, random_state=42),\n",
       " 'Logistic Regression': LogisticRegression(C=0.1, random_state=42),\n",
       " 'Random Forest': RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792f08c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naïve Bayes\n",
      "==================================================\n",
      "Accuracy: 0.6402439024390244\n",
      "Precision: 0.6518987341772152\n",
      "Recall: 0.9626168224299065\n",
      "F-measure: 0.7773584905660378\n",
      "Model: SVM\n",
      "==================================================\n",
      "Accuracy: 0.6524390243902439\n",
      "Precision: 0.6524390243902439\n",
      "Recall: 1.0\n",
      "F-measure: 0.7896678966789668\n",
      "Model: Logistic Regression\n",
      "==================================================\n",
      "Accuracy: 0.6463414634146342\n",
      "Precision: 0.855072463768116\n",
      "Recall: 0.5514018691588785\n",
      "F-measure: 0.6704545454545454\n",
      "Model: Random Forest\n",
      "==================================================\n",
      "Accuracy: 0.7804878048780488\n",
      "Precision: 0.7933884297520661\n",
      "Recall: 0.897196261682243\n",
      "F-measure: 0.8421052631578947\n",
      "CPU times: user 29.1 ms, sys: 2.58 ms, total: 31.7 ms\n",
      "Wall time: 29.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': ['Naïve Bayes', 'SVM', 'Logistic Regression', 'Random Forest'],\n",
       " 'Accuracy': [0.6402439024390244,\n",
       "  0.6524390243902439,\n",
       "  0.6463414634146342,\n",
       "  0.7804878048780488],\n",
       " 'Precision': [0.6518987341772152,\n",
       "  0.6524390243902439,\n",
       "  0.855072463768116,\n",
       "  0.7933884297520661],\n",
       " 'Recall': [0.9626168224299065, 1.0, 0.5514018691588785, 0.897196261682243],\n",
       " 'F1 Score': [0.7773584905660378,\n",
       "  0.7896678966789668,\n",
       "  0.6704545454545454,\n",
       "  0.8421052631578947]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "result = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": [],\n",
    "}\n",
    "\n",
    "for model_name in best_estimators:\n",
    "    model = best_estimators[model_name]\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    result[\"Model\"].append(model_name)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F-measure:\", f_measure)\n",
    "\n",
    "    result[\"Accuracy\"].append(accuracy)\n",
    "    result[\"Precision\"].append(precision)\n",
    "    result[\"Recall\"].append(recall)\n",
    "    result[\"F1 Score\"].append(f_measure)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db9e6036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>0.640244</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>0.962617</td>\n",
       "      <td>0.777358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.551402</td>\n",
       "      <td>0.670455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0          Naïve Bayes  0.640244   0.651899  0.962617  0.777358\n",
       "1                  SVM  0.652439   0.652439  1.000000  0.789668\n",
       "2  Logistic Regression  0.646341   0.855072  0.551402  0.670455\n",
       "3        Random Forest  0.780488   0.793388  0.897196  0.842105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "perf_ds = Dataset.from_dict(result).to_pandas()\n",
    "perf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d0c128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>64.024390</td>\n",
       "      <td>65.189873</td>\n",
       "      <td>96.261682</td>\n",
       "      <td>77.735849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>65.243902</td>\n",
       "      <td>65.243902</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>78.966790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>64.634146</td>\n",
       "      <td>85.507246</td>\n",
       "      <td>55.140187</td>\n",
       "      <td>67.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>78.048780</td>\n",
       "      <td>79.338843</td>\n",
       "      <td>89.719626</td>\n",
       "      <td>84.210526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy  Precision      Recall   F1 Score\n",
       "Model                                                           \n",
       "Naïve Bayes          64.024390  65.189873   96.261682  77.735849\n",
       "SVM                  65.243902  65.243902  100.000000  78.966790\n",
       "Logistic Regression  64.634146  85.507246   55.140187  67.045455\n",
       "Random Forest        78.048780  79.338843   89.719626  84.210526"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = perf_ds.set_index(perf_ds.columns[0]).mul(100)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7e6f8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>64.0%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>96.3%</td>\n",
       "      <td>77.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>65.2%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>79.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>64.6%</td>\n",
       "      <td>85.5%</td>\n",
       "      <td>55.1%</td>\n",
       "      <td>67.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>78.0%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>89.7%</td>\n",
       "      <td>84.2%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy Precision  Recall F1 Score\n",
       "Model                                                  \n",
       "Naïve Bayes            64.0%     65.2%   96.3%    77.7%\n",
       "SVM                    65.2%     65.2%  100.0%    79.0%\n",
       "Logistic Regression    64.6%     85.5%   55.1%    67.0%\n",
       "Random Forest          78.0%     79.3%   89.7%    84.2%"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in res2.select_dtypes(include=[\"number\"]).columns:\n",
    "    res2[key] = res2[key].apply(\"{:.1f}%\".format)\n",
    "\n",
    "res2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
