{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cdf1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "==================================================\n",
      "Best Parameters:  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8369098712446352\n",
      "Precision: 0.8015267175572519\n",
      "Recall: 0.8974358974358975\n",
      "F1 Score: 0.8467741935483871\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8369098712446352\n",
      "Precision: 0.8319327731092437\n",
      "Recall: 0.8461538461538461\n",
      "F1 Score: 0.8389830508474577\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.9399141630901288\n",
      "Precision: 0.9903846153846154\n",
      "Recall: 0.8879310344827587\n",
      "F1 Score: 0.9363636363636364\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.7639484978540773\n",
      "Precision: 0.9295774647887324\n",
      "Recall: 0.5689655172413793\n",
      "F1 Score: 0.7058823529411765\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.8577586206896551\n",
      "Precision: 0.9882352941176471\n",
      "Recall: 0.7241379310344828\n",
      "F1 Score: 0.8358208955223881\n",
      "\n",
      "Average Accuracy: 0.8470882048246263\n",
      "Average Precision: 0.908331372991498\n",
      "Average Recall: 0.7849248452696729\n",
      "Average F1 Score: 0.8327648258446091\n",
      "\n",
      "Model: Logistic Regression\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inflaton/miniconda3/envs/cs701/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/inflaton/miniconda3/envs/cs701/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/inflaton/miniconda3/envs/cs701/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/inflaton/miniconda3/envs/cs701/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/inflaton/miniconda3/envs/cs701/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/inflaton/miniconda3/envs/cs701/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.66149919        nan 0.66149919        nan 0.66149919]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.1, 'penalty': 'l2'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.6394849785407726\n",
      "Precision: 0.6633663366336634\n",
      "Recall: 0.5726495726495726\n",
      "F1 Score: 0.6146788990825689\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.7467811158798283\n",
      "Precision: 0.7843137254901961\n",
      "Recall: 0.6837606837606838\n",
      "F1 Score: 0.7305936073059361\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.703862660944206\n",
      "Precision: 0.7582417582417582\n",
      "Recall: 0.5948275862068966\n",
      "F1 Score: 0.6666666666666666\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.5708154506437768\n",
      "Precision: 0.6739130434782609\n",
      "Recall: 0.2672413793103448\n",
      "F1 Score: 0.38271604938271603\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.646551724137931\n",
      "Precision: 0.7428571428571429\n",
      "Recall: 0.4482758620689655\n",
      "F1 Score: 0.5591397849462366\n",
      "\n",
      "Average Accuracy: 0.661499186029303\n",
      "Average Precision: 0.7245384013402043\n",
      "Average Recall: 0.5133510167992927\n",
      "Average F1 Score: 0.5907590014768248\n",
      "\n",
      "Model: Naïve Bayes\n",
      "==================================================\n",
      "Best Parameters:  {}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.51931330472103\n",
      "Precision: 0.5109170305676856\n",
      "Recall: 1.0\n",
      "F1 Score: 0.676300578034682\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.5278969957081545\n",
      "Precision: 0.515695067264574\n",
      "Recall: 0.9829059829059829\n",
      "F1 Score: 0.6764705882352943\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.5236051502145923\n",
      "Precision: 0.511520737327189\n",
      "Recall: 0.9568965517241379\n",
      "F1 Score: 0.6666666666666666\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.4978540772532189\n",
      "Precision: 0.4975369458128079\n",
      "Recall: 0.8706896551724138\n",
      "F1 Score: 0.6332288401253918\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.5258620689655172\n",
      "Precision: 0.5135135135135135\n",
      "Recall: 0.9827586206896551\n",
      "F1 Score: 0.6745562130177514\n",
      "\n",
      "Average Accuracy: 0.5189063193725025\n",
      "Average Precision: 0.509836658897154\n",
      "Average Recall: 0.9586501620984379\n",
      "Average F1 Score: 0.6654445772159572\n",
      "\n",
      "Model: SVM\n",
      "==================================================\n",
      "Best Parameters:  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8497854077253219\n",
      "Precision: 0.7697368421052632\n",
      "Recall: 1.0\n",
      "F1 Score: 0.8698884758364311\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8841201716738197\n",
      "Precision: 0.8125\n",
      "Recall: 1.0\n",
      "F1 Score: 0.896551724137931\n",
      "\n",
      "Average Accuracy: 0.866952789699571\n",
      "Average Precision: 0.7911184210526319\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.8832200999871809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Read the data into a dataframe\n",
    "df = pd.read_csv('cleaned_sentiment_data.csv')\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df[['total_positive_direct_mentions',\n",
    "        'total_negative_direct_mentions', \n",
    "        'total_positive_indirect_mentions',\n",
    "        'total_negative_indirect_mentions', \n",
    "        'soft_cap']]\n",
    "y = df['ico_success']\n",
    "\n",
    "# Perform Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Define the parameter grids for grid search\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "lr_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "nb_param_grid = {}\n",
    "\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Random Forest': (RandomForestClassifier(random_state=42), rf_param_grid),\n",
    "    'Logistic Regression': (LogisticRegression(random_state=42), lr_param_grid),\n",
    "    'Naïve Bayes': (GaussianNB(), nb_param_grid),\n",
    "    'SVM': (SVC(random_state=42), svm_param_grid)\n",
    "}\n",
    "\n",
    "# Perform grid search and cross-validation for each model\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Perform grid search with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # Print the best parameters and the corresponding score\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    print()\n",
    "\n",
    "    # Perform 5-fold cross-validation with the best model\n",
    "    cv_results = cross_validate(grid_search.best_estimator_, X_resampled, y_resampled, cv=5, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    overfitted_folds = 0  # Counter for overfitted folds\n",
    "    for fold_idx, fold_result in enumerate(cv_results['test_accuracy']):\n",
    "        if fold_result == 1.0:  # Check for overfitted fold\n",
    "            overfitted_folds += 1\n",
    "            continue  # Skip overfitted fold\n",
    "\n",
    "        print(f\"Fold {fold_idx+1}:\")\n",
    "        print(f\"Accuracy: {fold_result}\")\n",
    "        print(f\"Precision: {cv_results['test_precision'][fold_idx]}\")\n",
    "        print(f\"Recall: {cv_results['test_recall'][fold_idx]}\")\n",
    "        print(f\"F1 Score: {cv_results['test_f1'][fold_idx]}\")\n",
    "        print()\n",
    "\n",
    "    # Calculate average results across non-overfitted folds\n",
    "    num_folds = len(cv_results['test_accuracy'])\n",
    "    num_non_overfitted_folds = num_folds - overfitted_folds\n",
    "    avg_accuracy = (sum(cv_results['test_accuracy']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_precision = (sum(cv_results['test_precision']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_recall = (sum(cv_results['test_recall']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_f1 = (sum(cv_results['test_f1']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "\n",
    "    # Print the average results\n",
    "    print(f\"Average Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Average Precision: {avg_precision}\")\n",
    "    print(f\"Average Recall: {avg_recall}\")\n",
    "    print(f\"Average F1 Score: {avg_f1}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c5a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBboost\n",
      "==================================================\n",
      "Best Parameters:  {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8283261802575107\n",
      "Precision: 0.808\n",
      "Recall: 0.8632478632478633\n",
      "F1 Score: 0.8347107438016529\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8583690987124464\n",
      "Precision: 0.868421052631579\n",
      "Recall: 0.8461538461538461\n",
      "F1 Score: 0.8571428571428572\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.927038626609442\n",
      "Precision: 1.0\n",
      "Recall: 0.853448275862069\n",
      "F1 Score: 0.9209302325581395\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.8240343347639485\n",
      "Precision: 1.0\n",
      "Recall: 0.646551724137931\n",
      "F1 Score: 0.7853403141361257\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.8577586206896551\n",
      "Precision: 1.0\n",
      "Recall: 0.7155172413793104\n",
      "F1 Score: 0.8341708542713567\n",
      "\n",
      "Average Accuracy: 0.8591053722066005\n",
      "Average Precision: 0.9352842105263157\n",
      "Average Recall: 0.784983790156204\n",
      "Average F1 Score: 0.8464590003820265\n",
      "\n",
      "Model: CatBoost\n",
      "==================================================\n",
      "Best Parameters:  {'depth': 10, 'iterations': 200, 'learning_rate': 0.1}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8454935622317596\n",
      "Precision: 0.7956204379562044\n",
      "Recall: 0.9316239316239316\n",
      "F1 Score: 0.8582677165354332\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8540772532188842\n",
      "Precision: 0.8608695652173913\n",
      "Recall: 0.8461538461538461\n",
      "F1 Score: 0.8534482758620691\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.9613733905579399\n",
      "Precision: 1.0\n",
      "Recall: 0.9224137931034483\n",
      "F1 Score: 0.9596412556053812\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.8283261802575107\n",
      "Precision: 1.0\n",
      "Recall: 0.6551724137931034\n",
      "F1 Score: 0.7916666666666666\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.8663793103448276\n",
      "Precision: 1.0\n",
      "Recall: 0.7327586206896551\n",
      "F1 Score: 0.8457711442786069\n",
      "\n",
      "Average Accuracy: 0.8711299393221845\n",
      "Average Precision: 0.9312980006347192\n",
      "Average Recall: 0.8176245210727968\n",
      "Average F1 Score: 0.8617590117896313\n",
      "\n",
      "Model: Random Forest\n",
      "==================================================\n",
      "Best Parameters:  {}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8454935622317596\n",
      "Precision: 0.813953488372093\n",
      "Recall: 0.8974358974358975\n",
      "F1 Score: 0.8536585365853658\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.871244635193133\n",
      "Precision: 0.8717948717948718\n",
      "Recall: 0.8717948717948718\n",
      "F1 Score: 0.8717948717948718\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.944206008583691\n",
      "Precision: 1.0\n",
      "Recall: 0.8879310344827587\n",
      "F1 Score: 0.9406392694063928\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.7896995708154506\n",
      "Precision: 1.0\n",
      "Recall: 0.5775862068965517\n",
      "F1 Score: 0.73224043715847\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.8577586206896551\n",
      "Precision: 1.0\n",
      "Recall: 0.7155172413793104\n",
      "F1 Score: 0.8341708542713567\n",
      "\n",
      "Average Accuracy: 0.861680479502738\n",
      "Average Precision: 0.9371496720333929\n",
      "Average Recall: 0.790053050397878\n",
      "Average F1 Score: 0.8465007938432914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "models = {\n",
    "    'XGBboost': XGBClassifier(random_state=42, learning_rate=0.03, max_depth=3, n_estimators=300, reg_lambda=2),\n",
    "    'CatBoost': CatBoostClassifier(random_state=42, iterations=200, depth=4, loss_function='Logloss',\n",
    "                                   l2_leaf_reg=1e-20, leaf_estimation_iterations=10, logging_level='Silent',\n",
    "                                   learning_rate=0.03),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# Define the parameter grids for grid search\n",
    "param_grids = {\n",
    "    'XGBboost': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.03, 0.1],\n",
    "        'max_depth': [3, 5, 10],\n",
    "        'reg_lambda': [1, 2, 5]\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'iterations': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.03, 0.1],\n",
    "        'depth': [3, 5, 10]\n",
    "    },\n",
    "    'Random Forest': {},\n",
    "}\n",
    "    \n",
    "# Perform grid search for each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Get the parameter grid for the current model\n",
    "    param_grid = param_grids[model_name]\n",
    "\n",
    "    # Perform grid search with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # Print the best parameters and the corresponding score\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    print()\n",
    "    \n",
    "    # Perform 5-fold cross-validation with the best model\n",
    "    cv_results = cross_validate(grid_search.best_estimator_, X_resampled, y_resampled, cv=5, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    overfitted_folds = 0  # Counter for overfitted folds\n",
    "    for fold_idx, fold_result in enumerate(cv_results['test_accuracy']):\n",
    "        if fold_result == 1.0:  # Check for overfitted fold\n",
    "            overfitted_folds += 1\n",
    "            continue  # Skip overfitted fold\n",
    "\n",
    "        print(f\"Fold {fold_idx+1}:\")\n",
    "        print(f\"Accuracy: {fold_result}\")\n",
    "        print(f\"Precision: {cv_results['test_precision'][fold_idx]}\")\n",
    "        print(f\"Recall: {cv_results['test_recall'][fold_idx]}\")\n",
    "        print(f\"F1 Score: {cv_results['test_f1'][fold_idx]}\")\n",
    "        print()\n",
    "\n",
    "    # Calculate average results across non-overfitted folds\n",
    "    num_folds = len(cv_results['test_accuracy'])\n",
    "    num_non_overfitted_folds = num_folds - overfitted_folds\n",
    "    avg_accuracy = (sum(cv_results['test_accuracy']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_precision = (sum(cv_results['test_precision']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_recall = (sum(cv_results['test_recall']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_f1 = (sum(cv_results['test_f1']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "\n",
    "    # Print the average results\n",
    "    print(f\"Average Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Average Precision: {avg_precision}\")\n",
    "    print(f\"Average Recall: {avg_recall}\")\n",
    "    print(f\"Average F1 Score: {avg_f1}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
