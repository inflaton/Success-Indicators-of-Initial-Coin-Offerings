{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cdf1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naïve Bayes\n",
      "==================================================\n",
      "Best Parameters:  {}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.51931330472103\n",
      "Precision: 0.5109170305676856\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6763005780346821\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.5278969957081545\n",
      "Precision: 0.515695067264574\n",
      "Recall: 0.9829059829059829\n",
      "F1 Score: 0.6764705882352942\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.5236051502145923\n",
      "Precision: 0.511520737327189\n",
      "Recall: 0.9568965517241379\n",
      "F1 Score: 0.6666666666666666\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.4978540772532189\n",
      "Precision: 0.4975369458128079\n",
      "Recall: 0.8706896551724138\n",
      "F1 Score: 0.6332288401253918\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.5258620689655172\n",
      "Precision: 0.5135135135135135\n",
      "Recall: 0.9827586206896551\n",
      "F1 Score: 0.6745562130177515\n",
      "\n",
      "Average Accuracy: 0.5189063193725025\n",
      "Average Precision: 0.509836658897154\n",
      "Average Recall: 0.9586501620984379\n",
      "Average F1 Score: 0.6654445772159572\n",
      "\n",
      "Model: SVM\n",
      "==================================================\n",
      "Best Parameters:  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8497854077253219\n",
      "Precision: 0.7697368421052632\n",
      "Recall: 1.0\n",
      "F1 Score: 0.8698884758364313\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8841201716738197\n",
      "Precision: 0.8125\n",
      "Recall: 1.0\n",
      "F1 Score: 0.896551724137931\n",
      "\n",
      "Average Accuracy: 0.866952789699571\n",
      "Average Precision: 0.7911184210526319\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.8832200999871809\n",
      "\n",
      "Model: Logistic Regression\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.67954714        nan 0.67010508        nan 0.67182181]\n",
      "  warnings.warn(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.1, 'penalty': 'l2'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.6695278969957081\n",
      "Precision: 0.6818181818181818\n",
      "Recall: 0.6410256410256411\n",
      "F1 Score: 0.6607929515418502\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.7296137339055794\n",
      "Precision: 0.7934782608695652\n",
      "Recall: 0.6239316239316239\n",
      "F1 Score: 0.6985645933014354\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.7553648068669528\n",
      "Precision: 0.7920792079207921\n",
      "Recall: 0.6896551724137931\n",
      "F1 Score: 0.7373271889400922\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.5708154506437768\n",
      "Precision: 0.6428571428571429\n",
      "Recall: 0.3103448275862069\n",
      "F1 Score: 0.4186046511627907\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.6724137931034483\n",
      "Precision: 0.7631578947368421\n",
      "Recall: 0.5\n",
      "F1 Score: 0.6041666666666666\n",
      "\n",
      "Average Accuracy: 0.679547136303093\n",
      "Average Precision: 0.7346781376405047\n",
      "Average Recall: 0.552991452991453\n",
      "Average F1 Score: 0.623891210322567\n",
      "\n",
      "Model: Random Forest\n",
      "==================================================\n",
      "Best Parameters:  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8369098712446352\n",
      "Precision: 0.8015267175572519\n",
      "Recall: 0.8974358974358975\n",
      "F1 Score: 0.8467741935483871\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8369098712446352\n",
      "Precision: 0.8319327731092437\n",
      "Recall: 0.8461538461538461\n",
      "F1 Score: 0.8389830508474576\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.9399141630901288\n",
      "Precision: 0.9903846153846154\n",
      "Recall: 0.8879310344827587\n",
      "F1 Score: 0.9363636363636364\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.7639484978540773\n",
      "Precision: 0.9295774647887324\n",
      "Recall: 0.5689655172413793\n",
      "F1 Score: 0.7058823529411765\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.8577586206896551\n",
      "Precision: 0.9882352941176471\n",
      "Recall: 0.7241379310344828\n",
      "F1 Score: 0.835820895522388\n",
      "\n",
      "Average Accuracy: 0.8470882048246263\n",
      "Average Precision: 0.908331372991498\n",
      "Average Recall: 0.7849248452696729\n",
      "Average F1 Score: 0.8327648258446091\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': ['Naïve Bayes', 'SVM', 'Logistic Regression', 'Random Forest'],\n",
       " 'Best Parameters': [{},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'penalty': 'l2'},\n",
       "  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}],\n",
       " 'Average Accuracy': [0.5189063193725025,\n",
       "  0.866952789699571,\n",
       "  0.679547136303093,\n",
       "  0.8470882048246263],\n",
       " 'Average Precision': [0.509836658897154,\n",
       "  0.7911184210526319,\n",
       "  0.7346781376405047,\n",
       "  0.908331372991498],\n",
       " 'Average Recall': [0.9586501620984379,\n",
       "  1.0,\n",
       "  0.552991452991453,\n",
       "  0.7849248452696729],\n",
       " 'Average F1 Score': [0.6654445772159572,\n",
       "  0.8832200999871809,\n",
       "  0.623891210322567,\n",
       "  0.8327648258446091]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Read the data into a dataframe\n",
    "df = pd.read_csv('cleaned_sentiment_data.csv')\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df[['total_positive_direct_mentions',\n",
    "        'total_negative_direct_mentions', \n",
    "        'total_positive_indirect_mentions',\n",
    "        'total_negative_indirect_mentions', \n",
    "        'soft_cap']]\n",
    "y = df['ico_success']\n",
    "\n",
    "# Perform Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Define the parameter grids for grid search\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "lr_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "nb_param_grid = {}\n",
    "\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"Naïve Bayes\": (GaussianNB(), nb_param_grid),\n",
    "    \"SVM\": (SVC(random_state=42), svm_param_grid),\n",
    "    \"Logistic Regression\": (LogisticRegression(random_state=42), lr_param_grid),\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42), rf_param_grid),\n",
    "}\n",
    "\n",
    "result = {\n",
    "    \"Model\": [],\n",
    "    \"Best Parameters\": [],\n",
    "    \"Average Accuracy\": [],\n",
    "    \"Average Precision\": [],\n",
    "    \"Average Recall\": [],\n",
    "    \"Average F1 Score\": [],\n",
    "}\n",
    "\n",
    "# Perform grid search and cross-validation for each model\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    result[\"Model\"].append(model_name)\n",
    "\n",
    "    # Perform grid search with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # Print the best parameters and the corresponding score\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    print()\n",
    "\n",
    "    result[\"Best Parameters\"].append(grid_search.best_params_)\n",
    "\n",
    "    # Perform 5-fold cross-validation with the best model\n",
    "    cv_results = cross_validate(grid_search.best_estimator_, X_resampled, y_resampled, cv=5, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    overfitted_folds = 0  # Counter for overfitted folds\n",
    "    for fold_idx, fold_result in enumerate(cv_results['test_accuracy']):\n",
    "        if fold_result == 1.0:  # Check for overfitted fold\n",
    "            overfitted_folds += 1\n",
    "            continue  # Skip overfitted fold\n",
    "\n",
    "        print(f\"Fold {fold_idx+1}:\")\n",
    "        print(f\"Accuracy: {fold_result}\")\n",
    "        print(f\"Precision: {cv_results['test_precision'][fold_idx]}\")\n",
    "        print(f\"Recall: {cv_results['test_recall'][fold_idx]}\")\n",
    "        print(f\"F1 Score: {cv_results['test_f1'][fold_idx]}\")\n",
    "        print()\n",
    "\n",
    "    # Calculate average results across non-overfitted folds\n",
    "    num_folds = len(cv_results['test_accuracy'])\n",
    "    num_non_overfitted_folds = num_folds - overfitted_folds\n",
    "    avg_accuracy = (sum(cv_results['test_accuracy']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_precision = (sum(cv_results['test_precision']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_recall = (sum(cv_results['test_recall']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_f1 = (sum(cv_results['test_f1']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "\n",
    "    # Print the average results\n",
    "    print(f\"Average Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Average Precision: {avg_precision}\")\n",
    "    print(f\"Average Recall: {avg_recall}\")\n",
    "    print(f\"Average F1 Score: {avg_f1}\")\n",
    "    print()\n",
    "\n",
    "    result[\"Average Accuracy\"].append(avg_accuracy)\n",
    "    result[\"Average Precision\"].append(avg_precision)\n",
    "    result[\"Average Recall\"].append(avg_recall)\n",
    "    result[\"Average F1 Score\"].append(avg_f1)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c5a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "perf_ds = Dataset.from_dict(result).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd16e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>{'C': None, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.518906</td>\n",
       "      <td>0.509837</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>0.665445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'ma...</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.791118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.1, 'gamma': None, 'kernel': None, 'max...</td>\n",
       "      <td>0.679547</td>\n",
       "      <td>0.734678</td>\n",
       "      <td>0.552991</td>\n",
       "      <td>0.623891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'C': None, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.847088</td>\n",
       "      <td>0.908331</td>\n",
       "      <td>0.784925</td>\n",
       "      <td>0.832765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                                    Best Parameters  \\\n",
       "0          Naïve Bayes  {'C': None, 'gamma': None, 'kernel': None, 'ma...   \n",
       "1                  SVM  {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'ma...   \n",
       "2  Logistic Regression  {'C': 0.1, 'gamma': None, 'kernel': None, 'max...   \n",
       "3        Random Forest  {'C': None, 'gamma': None, 'kernel': None, 'ma...   \n",
       "\n",
       "   Average Accuracy  Average Precision  Average Recall  Average F1 Score  \n",
       "0          0.518906           0.509837        0.958650          0.665445  \n",
       "1          0.866953           0.791118        1.000000          0.883220  \n",
       "2          0.679547           0.734678        0.552991          0.623891  \n",
       "3          0.847088           0.908331        0.784925          0.832765  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3b6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = perf_ds.drop(columns=[\"Best Parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fafaa856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>51.890632</td>\n",
       "      <td>50.983666</td>\n",
       "      <td>95.865016</td>\n",
       "      <td>66.544458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>86.695279</td>\n",
       "      <td>79.111842</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.322010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>67.954714</td>\n",
       "      <td>73.467814</td>\n",
       "      <td>55.299145</td>\n",
       "      <td>62.389121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>84.708820</td>\n",
       "      <td>90.833137</td>\n",
       "      <td>78.492485</td>\n",
       "      <td>83.276483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Average Accuracy  Average Precision  Average Recall  \\\n",
       "Model                                                                      \n",
       "Naïve Bayes                 51.890632          50.983666       95.865016   \n",
       "SVM                         86.695279          79.111842      100.000000   \n",
       "Logistic Regression         67.954714          73.467814       55.299145   \n",
       "Random Forest               84.708820          90.833137       78.492485   \n",
       "\n",
       "                     Average F1 Score  \n",
       "Model                                  \n",
       "Naïve Bayes                 66.544458  \n",
       "SVM                         88.322010  \n",
       "Logistic Regression         62.389121  \n",
       "Random Forest               83.276483  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = res2.set_index(res2.columns[0]).mul(100)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3525e951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>51.9%</td>\n",
       "      <td>51.0%</td>\n",
       "      <td>95.9%</td>\n",
       "      <td>66.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>86.7%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>88.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>68.0%</td>\n",
       "      <td>73.5%</td>\n",
       "      <td>55.3%</td>\n",
       "      <td>62.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>84.7%</td>\n",
       "      <td>90.8%</td>\n",
       "      <td>78.5%</td>\n",
       "      <td>83.3%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Average Accuracy Average Precision Average Recall  \\\n",
       "Model                                                                   \n",
       "Naïve Bayes                    51.9%             51.0%          95.9%   \n",
       "SVM                            86.7%             79.1%         100.0%   \n",
       "Logistic Regression            68.0%             73.5%          55.3%   \n",
       "Random Forest                  84.7%             90.8%          78.5%   \n",
       "\n",
       "                    Average F1 Score  \n",
       "Model                                 \n",
       "Naïve Bayes                    66.5%  \n",
       "SVM                            88.3%  \n",
       "Logistic Regression            62.4%  \n",
       "Random Forest                  83.3%  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in res2.select_dtypes(include=[\"number\"]).columns:\n",
    "    res2[key] = res2[key].apply(\"{:.1f}%\".format)\n",
    "\n",
    "res2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
