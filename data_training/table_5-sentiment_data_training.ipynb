{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cdf1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Na√Øve Bayes\n",
      "==================================================\n",
      "Best Parameters:  {}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.4842105263157895\n",
      "Precision: 0.4444444444444444\n",
      "Recall: 0.12631578947368421\n",
      "F1 Score: 0.19672131147540983\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 0.9789473684210527\n",
      "F1 Score: 0.6619217081850534\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.5105263157894737\n",
      "Precision: 0.5055555555555555\n",
      "Recall: 0.9578947368421052\n",
      "F1 Score: 0.6618181818181819\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.49473684210526314\n",
      "Precision: 0.4972375690607735\n",
      "Recall: 0.9473684210526315\n",
      "F1 Score: 0.6521739130434783\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.5263157894736842\n",
      "Precision: 0.5159235668789809\n",
      "Recall: 0.8526315789473684\n",
      "F1 Score: 0.6428571428571429\n",
      "\n",
      "Average Accuracy: 0.503157894736842\n",
      "Average Precision: 0.4926322271879509\n",
      "Average Recall: 0.7726315789473684\n",
      "Average F1 Score: 0.5630984514758531\n",
      "\n",
      "Model: SVM\n",
      "==================================================\n",
      "Best Parameters:  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8473684210526315\n",
      "Precision: 0.7661290322580645\n",
      "Recall: 1.0\n",
      "F1 Score: 0.867579908675799\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8894736842105263\n",
      "Precision: 0.8189655172413793\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9004739336492891\n",
      "\n",
      "Average Accuracy: 0.8684210526315788\n",
      "Average Precision: 0.792547274749722\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.884026921162544\n",
      "\n",
      "Model: Logistic Regression\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.70315789        nan 0.7               nan 0.69894737]\n",
      "  warnings.warn(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.1, 'penalty': 'l2'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.6789473684210526\n",
      "Precision: 0.7125\n",
      "Recall: 0.6\n",
      "F1 Score: 0.6514285714285715\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.6526315789473685\n",
      "Precision: 0.6705882352941176\n",
      "Recall: 0.6\n",
      "F1 Score: 0.6333333333333333\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.7473684210526316\n",
      "Precision: 0.7640449438202247\n",
      "Recall: 0.7157894736842105\n",
      "F1 Score: 0.7391304347826086\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.7\n",
      "Precision: 0.7878787878787878\n",
      "Recall: 0.5473684210526316\n",
      "F1 Score: 0.6459627329192547\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.7368421052631579\n",
      "Precision: 0.835820895522388\n",
      "Recall: 0.5894736842105263\n",
      "F1 Score: 0.691358024691358\n",
      "\n",
      "Average Accuracy: 0.7031578947368421\n",
      "Average Precision: 0.7541665725031036\n",
      "Average Recall: 0.6105263157894737\n",
      "Average F1 Score: 0.6722426194310251\n",
      "\n",
      "Model: Random Forest\n",
      "==================================================\n",
      "Best Parameters:  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8\n",
      "Precision: 0.7878787878787878\n",
      "Recall: 0.8210526315789474\n",
      "F1 Score: 0.8041237113402062\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8473684210526315\n",
      "Precision: 0.851063829787234\n",
      "Recall: 0.8421052631578947\n",
      "F1 Score: 0.8465608465608465\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.8947368421052632\n",
      "Precision: 0.987012987012987\n",
      "Recall: 0.8\n",
      "F1 Score: 0.8837209302325582\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.9\n",
      "Precision: 0.975\n",
      "Recall: 0.8210526315789474\n",
      "F1 Score: 0.8914285714285715\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.8842105263157894\n",
      "Precision: 0.9866666666666667\n",
      "Recall: 0.7789473684210526\n",
      "F1 Score: 0.8705882352941177\n",
      "\n",
      "Average Accuracy: 0.8652631578947367\n",
      "Average Precision: 0.9175244542691351\n",
      "Average Recall: 0.8126315789473683\n",
      "Average F1 Score: 0.85928445897126\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': ['Na√Øve Bayes', 'SVM', 'Logistic Regression', 'Random Forest'],\n",
       " 'Best Parameters': [{},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'penalty': 'l2'},\n",
       "  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}],\n",
       " 'Average Accuracy': [0.503157894736842,\n",
       "  0.8684210526315788,\n",
       "  0.7031578947368421,\n",
       "  0.8652631578947367],\n",
       " 'Average Precision': [0.4926322271879509,\n",
       "  0.792547274749722,\n",
       "  0.7541665725031036,\n",
       "  0.9175244542691351],\n",
       " 'Average Recall': [0.7726315789473684,\n",
       "  1.0,\n",
       "  0.6105263157894737,\n",
       "  0.8126315789473683],\n",
       " 'Average F1 Score': [0.5630984514758531,\n",
       "  0.884026921162544,\n",
       "  0.6722426194310251,\n",
       "  0.85928445897126]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data into a dataframe\n",
    "df = pd.read_csv(\"cleaned_sentiment_data.csv\")\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df[\n",
    "    [\n",
    "        \"total_positive_direct_mentions\",\n",
    "        \"total_negative_direct_mentions\",\n",
    "        \"total_positive_indirect_mentions\",\n",
    "        \"total_negative_indirect_mentions\",\n",
    "        \"soft_cap\",\n",
    "    ]\n",
    "]\n",
    "y = df[\"ico_success\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Perform Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the parameter grids for grid search\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "lr_param_grid = {\"C\": [0.1, 1, 10], \"penalty\": [\"l1\", \"l2\"]}\n",
    "\n",
    "nb_param_grid = {}\n",
    "\n",
    "svm_param_grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"gamma\": [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "}\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"Na√Øve Bayes\": (GaussianNB(), nb_param_grid),\n",
    "    \"SVM\": (SVC(random_state=42), svm_param_grid),\n",
    "    \"Logistic Regression\": (LogisticRegression(random_state=42), lr_param_grid),\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42), rf_param_grid),\n",
    "}\n",
    "\n",
    "result = {\n",
    "    \"Model\": [],\n",
    "    \"Best Parameters\": [],\n",
    "    \"Average Accuracy\": [],\n",
    "    \"Average Precision\": [],\n",
    "    \"Average Recall\": [],\n",
    "    \"Average F1 Score\": [],\n",
    "}\n",
    "\n",
    "best_estimators = {}\n",
    "\n",
    "# Perform grid search and cross-validation for each model\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    result[\"Model\"].append(model_name)\n",
    "\n",
    "    # Perform grid search with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model, param_grid=param_grid, cv=5, scoring=\"accuracy\"\n",
    "    )\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # Print the best parameters and the corresponding score\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    print()\n",
    "\n",
    "    result[\"Best Parameters\"].append(grid_search.best_params_)\n",
    "\n",
    "    best_estimators[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    # Perform 5-fold cross-validation with the best model\n",
    "    cv_results = cross_validate(\n",
    "        grid_search.best_estimator_,\n",
    "        X_resampled,\n",
    "        y_resampled,\n",
    "        cv=5,\n",
    "        scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    "    )\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    overfitted_folds = 0  # Counter for overfitted folds\n",
    "    for fold_idx, fold_result in enumerate(cv_results[\"test_accuracy\"]):\n",
    "        if fold_result == 1.0:  # Check for overfitted fold\n",
    "            overfitted_folds += 1\n",
    "            continue  # Skip overfitted fold\n",
    "\n",
    "        print(f\"Fold {fold_idx+1}:\")\n",
    "        print(f\"Accuracy: {fold_result}\")\n",
    "        print(f\"Precision: {cv_results['test_precision'][fold_idx]}\")\n",
    "        print(f\"Recall: {cv_results['test_recall'][fold_idx]}\")\n",
    "        print(f\"F1 Score: {cv_results['test_f1'][fold_idx]}\")\n",
    "        print()\n",
    "\n",
    "    # Calculate results across non-overfitted folds\n",
    "    num_folds = len(cv_results[\"test_accuracy\"])\n",
    "    num_non_overfitted_folds = num_folds - overfitted_folds\n",
    "    avg_accuracy = (\n",
    "        sum(cv_results[\"test_accuracy\"]) - (overfitted_folds * 1)\n",
    "    ) / num_non_overfitted_folds\n",
    "    avg_precision = (\n",
    "        sum(cv_results[\"test_precision\"]) - (overfitted_folds * 1)\n",
    "    ) / num_non_overfitted_folds\n",
    "    avg_recall = (\n",
    "        sum(cv_results[\"test_recall\"]) - (overfitted_folds * 1)\n",
    "    ) / num_non_overfitted_folds\n",
    "    avg_f1 = (\n",
    "        sum(cv_results[\"test_f1\"]) - (overfitted_folds * 1)\n",
    "    ) / num_non_overfitted_folds\n",
    "\n",
    "    # Print the average results\n",
    "    print(f\"Average Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Average Precision: {avg_precision}\")\n",
    "    print(f\"Average Recall: {avg_recall}\")\n",
    "    print(f\"Average F1 Score: {avg_f1}\")\n",
    "    print()\n",
    "\n",
    "    result[\"Average Accuracy\"].append(avg_accuracy)\n",
    "    result[\"Average Precision\"].append(avg_precision)\n",
    "    result[\"Average Recall\"].append(avg_recall)\n",
    "    result[\"Average F1 Score\"].append(avg_f1)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c5a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "perf_ds = Dataset.from_dict(result).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd16e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Na√Øve Bayes</td>\n",
       "      <td>{'C': None, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.503158</td>\n",
       "      <td>0.492632</td>\n",
       "      <td>0.772632</td>\n",
       "      <td>0.563098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'ma...</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.792547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.1, 'gamma': None, 'kernel': None, 'max...</td>\n",
       "      <td>0.703158</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.610526</td>\n",
       "      <td>0.672243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'C': None, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.865263</td>\n",
       "      <td>0.917524</td>\n",
       "      <td>0.812632</td>\n",
       "      <td>0.859284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                                    Best Parameters  \\\n",
       "0          Na√Øve Bayes  {'C': None, 'gamma': None, 'kernel': None, 'ma...   \n",
       "1                  SVM  {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'ma...   \n",
       "2  Logistic Regression  {'C': 0.1, 'gamma': None, 'kernel': None, 'max...   \n",
       "3        Random Forest  {'C': None, 'gamma': None, 'kernel': None, 'ma...   \n",
       "\n",
       "   Average Accuracy  Average Precision  Average Recall  Average F1 Score  \n",
       "0          0.503158           0.492632        0.772632          0.563098  \n",
       "1          0.868421           0.792547        1.000000          0.884027  \n",
       "2          0.703158           0.754167        0.610526          0.672243  \n",
       "3          0.865263           0.917524        0.812632          0.859284  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3b6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = perf_ds.drop(columns=[\"Best Parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fafaa856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Na√Øve Bayes</th>\n",
       "      <td>50.315789</td>\n",
       "      <td>49.263223</td>\n",
       "      <td>77.263158</td>\n",
       "      <td>56.309845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>86.842105</td>\n",
       "      <td>79.254727</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.402692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>70.315789</td>\n",
       "      <td>75.416657</td>\n",
       "      <td>61.052632</td>\n",
       "      <td>67.224262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>86.526316</td>\n",
       "      <td>91.752445</td>\n",
       "      <td>81.263158</td>\n",
       "      <td>85.928446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Average Accuracy  Average Precision  Average Recall  \\\n",
       "Model                                                                      \n",
       "Na√Øve Bayes                 50.315789          49.263223       77.263158   \n",
       "SVM                         86.842105          79.254727      100.000000   \n",
       "Logistic Regression         70.315789          75.416657       61.052632   \n",
       "Random Forest               86.526316          91.752445       81.263158   \n",
       "\n",
       "                     Average F1 Score  \n",
       "Model                                  \n",
       "Na√Øve Bayes                 56.309845  \n",
       "SVM                         88.402692  \n",
       "Logistic Regression         67.224262  \n",
       "Random Forest               85.928446  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = res2.set_index(res2.columns[0]).mul(100)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3525e951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Na√Øve Bayes</th>\n",
       "      <td>50.3%</td>\n",
       "      <td>49.3%</td>\n",
       "      <td>77.3%</td>\n",
       "      <td>56.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>86.8%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>88.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>70.3%</td>\n",
       "      <td>75.4%</td>\n",
       "      <td>61.1%</td>\n",
       "      <td>67.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>86.5%</td>\n",
       "      <td>91.8%</td>\n",
       "      <td>81.3%</td>\n",
       "      <td>85.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Average Accuracy Average Precision Average Recall  \\\n",
       "Model                                                                   \n",
       "Na√Øve Bayes                    50.3%             49.3%          77.3%   \n",
       "SVM                            86.8%             79.3%         100.0%   \n",
       "Logistic Regression            70.3%             75.4%          61.1%   \n",
       "Random Forest                  86.5%             91.8%          81.3%   \n",
       "\n",
       "                    Average F1 Score  \n",
       "Model                                 \n",
       "Na√Øve Bayes                    56.3%  \n",
       "SVM                            88.4%  \n",
       "Logistic Regression            67.2%  \n",
       "Random Forest                  85.9%  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in res2.select_dtypes(include=[\"number\"]).columns:\n",
    "    res2[key] = res2[key].apply(\"{:.1f}%\".format)\n",
    "\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89f17f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Na√Øve Bayes': GaussianNB(),\n",
       " 'SVM': SVC(C=1, gamma=0.01, random_state=42),\n",
       " 'Logistic Regression': LogisticRegression(C=0.1, random_state=42),\n",
       " 'Random Forest': RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311f743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Na√Øve Bayes\n",
      "==================================================\n",
      "Accuracy: 0.6585365853658537\n",
      "Precision: 0.660377358490566\n",
      "Recall: 0.9813084112149533\n",
      "F-measure: 0.7894736842105263\n",
      "Model: SVM\n",
      "==================================================\n",
      "Accuracy: 0.6524390243902439\n",
      "Precision: 0.6524390243902439\n",
      "Recall: 1.0\n",
      "F-measure: 0.7896678966789668\n",
      "Model: Logistic Regression\n",
      "==================================================\n",
      "Accuracy: 0.6646341463414634\n",
      "Precision: 0.8170731707317073\n",
      "Recall: 0.6261682242990654\n",
      "F-measure: 0.708994708994709\n",
      "Model: Random Forest\n",
      "==================================================\n",
      "Accuracy: 0.7378048780487805\n",
      "Precision: 0.753968253968254\n",
      "Recall: 0.8878504672897196\n",
      "F-measure: 0.8154506437768241\n",
      "CPU times: user 18.4 ms, sys: 1.34 ms, total: 19.8 ms\n",
      "Wall time: 18.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': ['Na√Øve Bayes', 'SVM', 'Logistic Regression', 'Random Forest'],\n",
       " 'Accuracy': [0.6585365853658537,\n",
       "  0.6524390243902439,\n",
       "  0.6646341463414634,\n",
       "  0.7378048780487805],\n",
       " 'Precision': [0.660377358490566,\n",
       "  0.6524390243902439,\n",
       "  0.8170731707317073,\n",
       "  0.753968253968254],\n",
       " 'Recall': [0.9813084112149533, 1.0, 0.6261682242990654, 0.8878504672897196],\n",
       " 'F1 Score': [0.7894736842105263,\n",
       "  0.7896678966789668,\n",
       "  0.708994708994709,\n",
       "  0.8154506437768241]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "result = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": [],\n",
    "}\n",
    "\n",
    "for model_name in best_estimators:\n",
    "    model = best_estimators[model_name]\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    result[\"Model\"].append(model_name)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F-measure:\", f_measure)\n",
    "\n",
    "    result[\"Accuracy\"].append(accuracy)\n",
    "    result[\"Precision\"].append(precision)\n",
    "    result[\"Recall\"].append(recall)\n",
    "    result[\"F1 Score\"].append(f_measure)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "322ff408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Na√Øve Bayes</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.708995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.815451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0          Na√Øve Bayes  0.658537   0.660377  0.981308  0.789474\n",
       "1                  SVM  0.652439   0.652439  1.000000  0.789668\n",
       "2  Logistic Regression  0.664634   0.817073  0.626168  0.708995\n",
       "3        Random Forest  0.737805   0.753968  0.887850  0.815451"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "perf_ds = Dataset.from_dict(result).to_pandas()\n",
    "perf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c38c9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Na√Øve Bayes</th>\n",
       "      <td>65.853659</td>\n",
       "      <td>66.037736</td>\n",
       "      <td>98.130841</td>\n",
       "      <td>78.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>65.243902</td>\n",
       "      <td>65.243902</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>78.966790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>66.463415</td>\n",
       "      <td>81.707317</td>\n",
       "      <td>62.616822</td>\n",
       "      <td>70.899471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>73.780488</td>\n",
       "      <td>75.396825</td>\n",
       "      <td>88.785047</td>\n",
       "      <td>81.545064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy  Precision      Recall   F1 Score\n",
       "Model                                                           \n",
       "Na√Øve Bayes          65.853659  66.037736   98.130841  78.947368\n",
       "SVM                  65.243902  65.243902  100.000000  78.966790\n",
       "Logistic Regression  66.463415  81.707317   62.616822  70.899471\n",
       "Random Forest        73.780488  75.396825   88.785047  81.545064"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = perf_ds.set_index(perf_ds.columns[0]).mul(100)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f5072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Na√Øve Bayes</th>\n",
       "      <td>65.9%</td>\n",
       "      <td>66.0%</td>\n",
       "      <td>98.1%</td>\n",
       "      <td>78.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>65.2%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>79.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>66.5%</td>\n",
       "      <td>81.7%</td>\n",
       "      <td>62.6%</td>\n",
       "      <td>70.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>73.8%</td>\n",
       "      <td>75.4%</td>\n",
       "      <td>88.8%</td>\n",
       "      <td>81.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy Precision  Recall F1 Score\n",
       "Model                                                  \n",
       "Na√Øve Bayes            65.9%     66.0%   98.1%    78.9%\n",
       "SVM                    65.2%     65.2%  100.0%    79.0%\n",
       "Logistic Regression    66.5%     81.7%   62.6%    70.9%\n",
       "Random Forest          73.8%     75.4%   88.8%    81.5%"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in res2.select_dtypes(include=[\"number\"]).columns:\n",
    "    res2[key] = res2[key].apply(\"{:.1f}%\".format)\n",
    "\n",
    "res2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
