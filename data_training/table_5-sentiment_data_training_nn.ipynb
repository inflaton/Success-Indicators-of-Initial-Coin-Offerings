{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cdf1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data into a dataframe\n",
    "df = pd.read_csv(\"cleaned_sentiment_data.csv\")\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df[\n",
    "    [\n",
    "        \"total_positive_direct_mentions\",\n",
    "        \"total_negative_direct_mentions\",\n",
    "        \"total_positive_indirect_mentions\",\n",
    "        \"total_negative_indirect_mentions\",\n",
    "        \"soft_cap\",\n",
    "    ]\n",
    "]\n",
    "y = df[\"ico_success\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326a40c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 816 entries, 0 to 815\n",
      "Data columns (total 5 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   total_positive_direct_mentions    816 non-null    int64  \n",
      " 1   total_negative_direct_mentions    816 non-null    int64  \n",
      " 2   total_positive_indirect_mentions  816 non-null    int64  \n",
      " 3   total_negative_indirect_mentions  816 non-null    int64  \n",
      " 4   soft_cap                          816 non-null    float64\n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 32.0 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d04a5",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903d797",
   "metadata": {},
   "source": [
    "To get started, we use a very simple classification problem and a very simple multi-layer perceptron architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aa2fcd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ef1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import SkorchDoctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a94d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab48b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea515f93",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c39fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_train.to_numpy().astype(np.float32), y_train.to_numpy().astype(np.int64)\n",
    "X_test, y_test = X_test.to_numpy().astype(np.float32), y_test.to_numpy().astype(\n",
    "    np.int64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4eccba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((652, 5), (652,), 0.7285276073619632)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f96e0",
   "metadata": {},
   "source": [
    "### Definition of the `PyTorch` classification `module`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec30b3a",
   "metadata": {},
   "source": [
    "This is just an MLP with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ab2fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features=5,\n",
    "        num_units=1024,\n",
    "        n_classes=2,\n",
    "        nonlin=F.relu,\n",
    "        dropout=0.1,\n",
    "        depth=2,\n",
    "        batchnorm=True,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.num_units = num_units\n",
    "        self.n_classes = n_classes\n",
    "        self.nonlin = nonlin\n",
    "        self.batchnorm = batchnorm\n",
    "        self.depth = depth\n",
    "\n",
    "        self.dense0 = nn.Linear(self.num_features, self.num_units)\n",
    "        self.nonlin = self.nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        layers = []\n",
    "        for i in range(1, self.depth):\n",
    "            layers.append(nn.Linear(self.num_units, self.num_units))\n",
    "        self.dense1 = nn.Sequential(*layers)\n",
    "\n",
    "        self.output = nn.Linear(self.num_units, self.n_classes)\n",
    "        self.bn = nn.BatchNorm1d(self.n_classes)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.nonlin(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "\n",
    "        if self.batchnorm:\n",
    "            X = self.bn(X)\n",
    "\n",
    "        X = F.softmax(X, dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3253b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\n",
    "    torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")  # use gpu\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f24c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"batch_size\": 20,\n",
    "    \"max_epochs\": 10,\n",
    "    \"module__depth\": 6,\n",
    "    \"module__dropout\": 0.4,\n",
    "    \"module__num_units\": 66,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22344fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints_dir: ./checkpoints exists\n",
      "deleting dir: ./checkpoints/cp1\n",
      "deleting dir: ./checkpoints/cp2\n",
      "deleting dir: ./checkpoints/cp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoints_dir = \"./checkpoints\"\n",
    "path = Path(checkpoints_dir)\n",
    "\n",
    "if path.exists():\n",
    "    print(f\"checkpoints_dir: {checkpoints_dir} exists\")\n",
    "    for root, dirs, files in os.walk(checkpoints_dir):\n",
    "        for file in files:\n",
    "            checkpoint = f\"{root}/{file}\"\n",
    "            print(f\"deleting file: {checkpoint}\")\n",
    "            os.unlink(checkpoint)\n",
    "        for dir in dirs:\n",
    "            checkpoint = f\"{root}/{dir}\"\n",
    "            print(f\"deleting dir: {checkpoint}\")\n",
    "            shutil.rmtree(checkpoint)\n",
    "else:\n",
    "    print(f\"checkpoints_dir: {checkpoints_dir} doesn't exist. creating it ...\")\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19da2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4391a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Checkpoint, TrainEndCheckpoint\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "cp = Checkpoint(dirname=f\"{checkpoints_dir}/cp1\")\n",
    "\n",
    "optimal = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.001,\n",
    "    batch_size=20,\n",
    "    module__depth=6,\n",
    "    module__num_units=66,\n",
    "    module__dropout=0.4,\n",
    "    device=device,\n",
    "    callbacks=[cp],\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "models[cp] = optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "297aa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ------------  ----  ------\n",
      "      1        \u001b[36m0.7821\u001b[0m       \u001b[32m0.4141\u001b[0m        \u001b[35m0.7576\u001b[0m     +  0.1524\n",
      "      2        \u001b[36m0.7059\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6522\u001b[0m     +  0.0509\n",
      "      3        0.7086       0.7031        0.7766        0.0555\n",
      "      4        \u001b[36m0.6942\u001b[0m       0.7266        0.7259        0.0515\n",
      "      5        \u001b[36m0.6812\u001b[0m       0.7266        0.6882        0.0493\n",
      "      6        0.6875       0.7266        0.6895        0.0452\n",
      "      7        \u001b[36m0.6811\u001b[0m       0.7266        0.6820        0.0461\n",
      "      8        \u001b[36m0.6751\u001b[0m       0.7266        0.6691        0.0467\n",
      "      9        \u001b[36m0.6740\u001b[0m       0.7266        0.6853        0.0430\n",
      "     10        \u001b[36m0.6727\u001b[0m       0.7266        0.6829        0.0423\n",
      "CPU times: user 865 ms, sys: 111 ms, total: 976 ms\n",
      "Wall time: 1.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=5, out_features=66, bias=True)\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "    (dense1): Sequential(\n",
       "      (0): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (1): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (2): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (3): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (4): Linear(in_features=66, out_features=66, bias=True)\n",
       "    )\n",
       "    (output): Linear(in_features=66, out_features=2, bias=True)\n",
       "    (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimal.fit(X[:640], y[:640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9c3a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import LoadInitState\n",
    "\n",
    "# load_state = LoadInitState(cp)\n",
    "cp2 = Checkpoint(dirname=f\"{checkpoints_dir}/cp2\")\n",
    "\n",
    "optimal2 = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=11,\n",
    "    lr=0.001,\n",
    "    batch_size=10,\n",
    "    module__depth=7,\n",
    "    module__num_units=66,\n",
    "    module__dropout=0.4,\n",
    "    device=device,\n",
    "    callbacks=[cp2],\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "models[cp2] = optimal2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8c9d6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ------------  ----  ------\n",
      "      1        \u001b[36m0.7052\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.7569\u001b[0m     +  0.1045\n",
      "      2        \u001b[36m0.7018\u001b[0m       0.7266        \u001b[35m0.7114\u001b[0m     +  0.0928\n",
      "      3        \u001b[36m0.6860\u001b[0m       0.7266        \u001b[35m0.6895\u001b[0m     +  0.0870\n",
      "      4        \u001b[36m0.6758\u001b[0m       0.7266        \u001b[35m0.6745\u001b[0m     +  0.0860\n",
      "      5        \u001b[36m0.6729\u001b[0m       0.7266        0.7048        0.0945\n",
      "      6        \u001b[36m0.6655\u001b[0m       0.7266        0.6869        0.0983\n",
      "      7        \u001b[36m0.6626\u001b[0m       0.7266        \u001b[35m0.6596\u001b[0m     +  0.1055\n",
      "      8        \u001b[36m0.6584\u001b[0m       0.7266        0.6844        0.1019\n",
      "      9        \u001b[36m0.6537\u001b[0m       0.7266        0.6647        0.0926\n",
      "     10        \u001b[36m0.6502\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6344\u001b[0m     +  0.0865\n",
      "     11        \u001b[36m0.6470\u001b[0m       0.7344        0.6369        0.0934\n",
      "CPU times: user 1.03 s, sys: 80.7 ms, total: 1.11 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = optimal2.fit(X[:640], y[:640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd9fe2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_state = LoadInitState(cp2)\n",
    "cp3 = Checkpoint(dirname=f\"{checkpoints_dir}/cp3\")\n",
    "\n",
    "optimal3 = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.001,\n",
    "    batch_size=20,\n",
    "    module__depth=6,\n",
    "    module__num_units=80,\n",
    "    module__dropout=0.4,\n",
    "    device=device,\n",
    "    callbacks=[cp3],\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "models[cp3] = optimal3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "785a099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ------------  ----  ------\n",
      "      1        \u001b[36m0.8001\u001b[0m       \u001b[32m0.2734\u001b[0m        \u001b[35m0.6922\u001b[0m     +  0.0554\n",
      "      2        \u001b[36m0.7031\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6740\u001b[0m     +  0.0482\n",
      "      3        0.7090       \u001b[32m0.6328\u001b[0m        0.6757        0.0499\n",
      "      4        \u001b[36m0.6982\u001b[0m       \u001b[32m0.7422\u001b[0m        0.6748        0.0458\n",
      "      5        \u001b[36m0.6886\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6731\u001b[0m     +  0.0511\n",
      "      6        \u001b[36m0.6849\u001b[0m       0.7344        \u001b[35m0.6683\u001b[0m     +  0.0461\n",
      "      7        \u001b[36m0.6813\u001b[0m       0.7422        \u001b[35m0.6669\u001b[0m     +  0.0496\n",
      "      8        0.6861       0.7266        0.7003        0.0447\n",
      "      9        \u001b[36m0.6710\u001b[0m       0.7422        \u001b[35m0.6663\u001b[0m     +  0.0450\n",
      "     10        0.6713       0.7422        \u001b[35m0.6600\u001b[0m     +  0.0460\n",
      "CPU times: user 468 ms, sys: 66.4 ms, total: 534 ms\n",
      "Wall time: 521 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = optimal3.fit(X[:640], y[:640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b46e394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: depth, dropout, num_units.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: depth, dropout, num_units.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: depth, dropout, num_units.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "CPU times: user 41.2 ms, sys: 865 µs, total: 42.1 ms\n",
      "Wall time: 40.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7985074626865671, './checkpoints/cp1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "checkpoints = [cp, cp2, cp3]\n",
    "\n",
    "best_f1 = 0\n",
    "best_y_pred = None\n",
    "best_net = None\n",
    "\n",
    "for checkpoint in models:\n",
    "    net = models[checkpoint]\n",
    "    net.initialize()\n",
    "    net.load_params(checkpoint=checkpoint)\n",
    "\n",
    "    y_pred = net.predict(X_test)\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "    if f_measure > best_f1:\n",
    "        best_f1 = f_measure\n",
    "        best_net = net\n",
    "        best_cp = checkpoint\n",
    "\n",
    "best_f1, best_cp.dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a664a8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.52 ms, sys: 3.93 ms, total: 8.45 ms\n",
      "Wall time: 7.42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = best_net.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "258c05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"Model\": [\"Naïve Bayes\", \"SVM\", \"Logistic Regression\", \"Random Forest\"],\n",
    "    \"Accuracy\": [\n",
    "        0.6585365853658537,\n",
    "        0.6524390243902439,\n",
    "        0.6646341463414634,\n",
    "        0.7378048780487805,\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        0.660377358490566,\n",
    "        0.6524390243902439,\n",
    "        0.8170731707317073,\n",
    "        0.753968253968254,\n",
    "    ],\n",
    "    \"Recall\": [0.9813084112149533, 1.0, 0.6261682242990654, 0.8878504672897196],\n",
    "    \"F1 Score\": [\n",
    "        0.7894736842105263,\n",
    "        0.7896678966789668,\n",
    "        0.708994708994709,\n",
    "        0.8154506437768241,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8635cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6707317073170732\n",
      "Precision: 0.6645962732919255\n",
      "Recall: 1.0\n",
      "F-measure: 0.7985074626865671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "model_name = \"Neural Network\"\n",
    "result[\"Model\"].append(model_name)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f_measure = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-measure:\", f_measure)\n",
    "\n",
    "result[\"Accuracy\"].append(accuracy)\n",
    "result[\"Precision\"].append(precision)\n",
    "result[\"Recall\"].append(recall)\n",
    "result[\"F1 Score\"].append(f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "defd70af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': ['Naïve Bayes',\n",
       "  'SVM',\n",
       "  'Logistic Regression',\n",
       "  'Random Forest',\n",
       "  'Neural Network'],\n",
       " 'Accuracy': [0.6585365853658537,\n",
       "  0.6524390243902439,\n",
       "  0.6646341463414634,\n",
       "  0.7378048780487805,\n",
       "  0.6707317073170732],\n",
       " 'Precision': [0.660377358490566,\n",
       "  0.6524390243902439,\n",
       "  0.8170731707317073,\n",
       "  0.753968253968254,\n",
       "  0.6645962732919255],\n",
       " 'Recall': [0.9813084112149533,\n",
       "  1.0,\n",
       "  0.6261682242990654,\n",
       "  0.8878504672897196,\n",
       "  1.0],\n",
       " 'F1 Score': [0.7894736842105263,\n",
       "  0.7896678966789668,\n",
       "  0.708994708994709,\n",
       "  0.8154506437768241,\n",
       "  0.7985074626865671]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9eea385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>65.9%</td>\n",
       "      <td>66.0%</td>\n",
       "      <td>98.1%</td>\n",
       "      <td>78.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>65.2%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>79.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>66.5%</td>\n",
       "      <td>81.7%</td>\n",
       "      <td>62.6%</td>\n",
       "      <td>70.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>73.8%</td>\n",
       "      <td>75.4%</td>\n",
       "      <td>88.8%</td>\n",
       "      <td>81.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>67.1%</td>\n",
       "      <td>66.5%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>79.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy Precision  Recall F1 Score\n",
       "Model                                                  \n",
       "Naïve Bayes            65.9%     66.0%   98.1%    78.9%\n",
       "SVM                    65.2%     65.2%  100.0%    79.0%\n",
       "Logistic Regression    66.5%     81.7%   62.6%    70.9%\n",
       "Random Forest          73.8%     75.4%   88.8%    81.5%\n",
       "Neural Network         67.1%     66.5%  100.0%    79.9%"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "perf_ds2 = Dataset.from_dict(result).to_pandas()\n",
    "res2 = perf_ds2.set_index(perf_ds2.columns[0]).mul(100)\n",
    "for key in res2.select_dtypes(include=[\"number\"]).columns:\n",
    "    res2[key] = res2[key].apply(\"{:.1f}%\".format)\n",
    "\n",
    "res2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
