{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea89806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naïve Bayes\n",
      "==================================================\n",
      "Best Parameters:  {}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.45263157894736844\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.09473684210526316\n",
      "F1 Score: 0.14754098360655737\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 0.968421052631579\n",
      "F1 Score: 0.6594982078853047\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 0.9473684210526315\n",
      "F1 Score: 0.6545454545454545\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.4789473684210526\n",
      "Precision: 0.48863636363636365\n",
      "Recall: 0.9052631578947369\n",
      "F1 Score: 0.6346863468634686\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.49473684210526314\n",
      "Precision: 0.4968553459119497\n",
      "Recall: 0.8315789473684211\n",
      "F1 Score: 0.6220472440944882\n",
      "\n",
      "Average Accuracy: 0.4852631578947369\n",
      "Average Precision: 0.4637650085763293\n",
      "Average Recall: 0.7494736842105263\n",
      "Average F1 Score: 0.5436636473990546\n",
      "\n",
      "Model: SVM\n",
      "==================================================\n",
      "Best Parameters:  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8473684210526315\n",
      "Precision: 0.7661290322580645\n",
      "Recall: 1.0\n",
      "F1 Score: 0.867579908675799\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8894736842105263\n",
      "Precision: 0.8189655172413793\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9004739336492891\n",
      "\n",
      "Average Accuracy: 0.8684210526315788\n",
      "Average Precision: 0.792547274749722\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.884026921162544\n",
      "\n",
      "Model: Logistic Regression\n",
      "==================================================\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.65368421        nan 0.65789474        nan 0.65894737]\n",
      "  warnings.warn(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.6473684210526316\n",
      "Precision: 0.6521739130434783\n",
      "Recall: 0.631578947368421\n",
      "F1 Score: 0.6417112299465241\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.6789473684210526\n",
      "Precision: 0.717948717948718\n",
      "Recall: 0.5894736842105263\n",
      "F1 Score: 0.6473988439306358\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.6947368421052632\n",
      "Precision: 0.7466666666666667\n",
      "Recall: 0.5894736842105263\n",
      "F1 Score: 0.6588235294117647\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.6157894736842106\n",
      "Precision: 0.6486486486486487\n",
      "Recall: 0.5052631578947369\n",
      "F1 Score: 0.5680473372781065\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.6578947368421053\n",
      "Precision: 0.7083333333333334\n",
      "Recall: 0.5368421052631579\n",
      "F1 Score: 0.6107784431137725\n",
      "\n",
      "Average Accuracy: 0.6589473684210526\n",
      "Average Precision: 0.694754255928169\n",
      "Average Recall: 0.5705263157894737\n",
      "Average F1 Score: 0.6253518767361608\n",
      "\n",
      "Model: Random Forest\n",
      "==================================================\n",
      "Best Parameters:  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Fold 1:\n",
      "Accuracy: 0.8578947368421053\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 0.8947368421052632\n",
      "F1 Score: 0.8629441624365483\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8526315789473684\n",
      "Precision: 0.8850574712643678\n",
      "Recall: 0.8105263157894737\n",
      "F1 Score: 0.8461538461538461\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.9315789473684211\n",
      "Precision: 0.9767441860465116\n",
      "Recall: 0.8842105263157894\n",
      "F1 Score: 0.9281767955801105\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.9421052631578948\n",
      "Precision: 0.9565217391304348\n",
      "Recall: 0.9263157894736842\n",
      "F1 Score: 0.9411764705882353\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.9105263157894737\n",
      "Precision: 0.9875\n",
      "Recall: 0.8315789473684211\n",
      "F1 Score: 0.9028571428571428\n",
      "\n",
      "Average Accuracy: 0.8989473684210527\n",
      "Average Precision: 0.9278313459549296\n",
      "Average Recall: 0.8694736842105264\n",
      "Average F1 Score: 0.8962616835231767\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': ['Naïve Bayes', 'SVM', 'Logistic Regression', 'Random Forest'],\n",
       " 'Best Parameters': [{},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'penalty': 'l2'},\n",
       "  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}],\n",
       " 'Average Accuracy': [0.4852631578947369,\n",
       "  0.8684210526315788,\n",
       "  0.6589473684210526,\n",
       "  0.8989473684210527],\n",
       " 'Average Precision': [0.4637650085763293,\n",
       "  0.792547274749722,\n",
       "  0.694754255928169,\n",
       "  0.9278313459549296],\n",
       " 'Average Recall': [0.7494736842105263,\n",
       "  1.0,\n",
       "  0.5705263157894737,\n",
       "  0.8694736842105264],\n",
       " 'Average F1 Score': [0.5436636473990546,\n",
       "  0.884026921162544,\n",
       "  0.6253518767361608,\n",
       "  0.8962616835231767]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data into a dataframe\n",
    "df = pd.read_csv('cleaned_engagement_data.csv')\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df[['total_direct_mentions', \n",
    "        'total_indirect_mentions', \n",
    "        'total_likes', \n",
    "        'total_retweets', \n",
    "        'total_project_followers', \n",
    "        'total_indirect_followers', \n",
    "        'soft_cap']]\n",
    "y = df['ico_success']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Perform Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the parameter grids for grid search\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "lr_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "nb_param_grid = {}\n",
    "\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Naïve Bayes': (GaussianNB(), nb_param_grid),\n",
    "    'SVM': (SVC(random_state=42), svm_param_grid),\n",
    "    'Logistic Regression': (LogisticRegression(random_state=42), lr_param_grid),\n",
    "    'Random Forest': (RandomForestClassifier(random_state=42), rf_param_grid),\n",
    "}\n",
    "\n",
    "result = {\n",
    "    \"Model\": [],\n",
    "    \"Best Parameters\": [],\n",
    "    \"Average Accuracy\": [],\n",
    "    \"Average Precision\": [],\n",
    "    \"Average Recall\": [],\n",
    "    \"Average F1 Score\": [],\n",
    "}\n",
    "\n",
    "best_estimators = {}\n",
    "\n",
    "# Perform grid search and cross-validation for each model\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    result[\"Model\"].append(model_name)\n",
    "\n",
    "    # Perform grid search with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # Print the best parameters and the corresponding score\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    print()\n",
    "\n",
    "    result[\"Best Parameters\"].append(grid_search.best_params_)\n",
    "\n",
    "    best_estimators[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    # Perform 5-fold cross-validation with the best model\n",
    "    cv_results = cross_validate(grid_search.best_estimator_, X_resampled, y_resampled, cv=5, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    overfitted_folds = 0  # Counter for overfitted folds\n",
    "    for fold_idx, fold_result in enumerate(cv_results['test_accuracy']):\n",
    "        if fold_result == 1.0:  # Check for overfitted fold\n",
    "            overfitted_folds += 1\n",
    "            continue  # Skip overfitted fold\n",
    "\n",
    "        print(f\"Fold {fold_idx+1}:\")\n",
    "        print(f\"Accuracy: {fold_result}\")\n",
    "        print(f\"Precision: {cv_results['test_precision'][fold_idx]}\")\n",
    "        print(f\"Recall: {cv_results['test_recall'][fold_idx]}\")\n",
    "        print(f\"F1 Score: {cv_results['test_f1'][fold_idx]}\")\n",
    "        print()\n",
    "\n",
    "    # Calculate average results across non-overfitted folds\n",
    "    num_folds = len(cv_results['test_accuracy'])\n",
    "    num_non_overfitted_folds = num_folds - overfitted_folds\n",
    "    avg_accuracy = (sum(cv_results['test_accuracy']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_precision = (sum(cv_results['test_precision']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_recall = (sum(cv_results['test_recall']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "    avg_f1 = (sum(cv_results['test_f1']) - (overfitted_folds*1)) / num_non_overfitted_folds\n",
    "\n",
    "    # Print the average results\n",
    "    print(f\"Average Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Average Precision: {avg_precision}\")\n",
    "    print(f\"Average Recall: {avg_recall}\")\n",
    "    print(f\"Average F1 Score: {avg_f1}\")\n",
    "    print()\n",
    "\n",
    "    result[\"Average Accuracy\"].append(avg_accuracy)\n",
    "    result[\"Average Precision\"].append(avg_precision)\n",
    "    result[\"Average Recall\"].append(avg_recall)\n",
    "    result[\"Average F1 Score\"].append(avg_f1)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a6db9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/miniconda3/envs/ico/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "perf_ds = Dataset.from_dict(result).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef88037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>{'C': None, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.485263</td>\n",
       "      <td>0.463765</td>\n",
       "      <td>0.749474</td>\n",
       "      <td>0.543664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'ma...</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.792547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 10.0, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.658947</td>\n",
       "      <td>0.694754</td>\n",
       "      <td>0.570526</td>\n",
       "      <td>0.625352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'C': None, 'gamma': None, 'kernel': None, 'ma...</td>\n",
       "      <td>0.898947</td>\n",
       "      <td>0.927831</td>\n",
       "      <td>0.869474</td>\n",
       "      <td>0.896262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                                    Best Parameters  \\\n",
       "0          Naïve Bayes  {'C': None, 'gamma': None, 'kernel': None, 'ma...   \n",
       "1                  SVM  {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'ma...   \n",
       "2  Logistic Regression  {'C': 10.0, 'gamma': None, 'kernel': None, 'ma...   \n",
       "3        Random Forest  {'C': None, 'gamma': None, 'kernel': None, 'ma...   \n",
       "\n",
       "   Average Accuracy  Average Precision  Average Recall  Average F1 Score  \n",
       "0          0.485263           0.463765        0.749474          0.543664  \n",
       "1          0.868421           0.792547        1.000000          0.884027  \n",
       "2          0.658947           0.694754        0.570526          0.625352  \n",
       "3          0.898947           0.927831        0.869474          0.896262  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91c8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = perf_ds.drop(columns=[\"Best Parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12dc6f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>48.526316</td>\n",
       "      <td>46.376501</td>\n",
       "      <td>74.947368</td>\n",
       "      <td>54.366365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>86.842105</td>\n",
       "      <td>79.254727</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.402692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>65.894737</td>\n",
       "      <td>69.475426</td>\n",
       "      <td>57.052632</td>\n",
       "      <td>62.535188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>89.894737</td>\n",
       "      <td>92.783135</td>\n",
       "      <td>86.947368</td>\n",
       "      <td>89.626168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Average Accuracy  Average Precision  Average Recall  \\\n",
       "Model                                                                      \n",
       "Naïve Bayes                 48.526316          46.376501       74.947368   \n",
       "SVM                         86.842105          79.254727      100.000000   \n",
       "Logistic Regression         65.894737          69.475426       57.052632   \n",
       "Random Forest               89.894737          92.783135       86.947368   \n",
       "\n",
       "                     Average F1 Score  \n",
       "Model                                  \n",
       "Naïve Bayes                 54.366365  \n",
       "SVM                         88.402692  \n",
       "Logistic Regression         62.535188  \n",
       "Random Forest               89.626168  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = res2.set_index(res2.columns[0]).mul(100)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7726b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>48.5%</td>\n",
       "      <td>46.4%</td>\n",
       "      <td>74.9%</td>\n",
       "      <td>54.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>86.8%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>88.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>65.9%</td>\n",
       "      <td>69.5%</td>\n",
       "      <td>57.1%</td>\n",
       "      <td>62.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>89.9%</td>\n",
       "      <td>92.8%</td>\n",
       "      <td>86.9%</td>\n",
       "      <td>89.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Average Accuracy Average Precision Average Recall  \\\n",
       "Model                                                                   \n",
       "Naïve Bayes                    48.5%             46.4%          74.9%   \n",
       "SVM                            86.8%             79.3%         100.0%   \n",
       "Logistic Regression            65.9%             69.5%          57.1%   \n",
       "Random Forest                  89.9%             92.8%          86.9%   \n",
       "\n",
       "                    Average F1 Score  \n",
       "Model                                 \n",
       "Naïve Bayes                    54.4%  \n",
       "SVM                            88.4%  \n",
       "Logistic Regression            62.5%  \n",
       "Random Forest                  89.6%  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in res2.select_dtypes(include=[\"number\"]).columns:\n",
    "    res2[key] = res2[key].apply(\"{:.1f}%\".format)\n",
    "\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "922eaba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Naïve Bayes': GaussianNB(),\n",
       " 'SVM': SVC(C=1, gamma=0.01, random_state=42),\n",
       " 'Logistic Regression': LogisticRegression(C=10, random_state=42),\n",
       " 'Random Forest': RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d34443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naïve Bayes\n",
      "==================================================\n",
      "Accuracy: 0.6463414634146342\n",
      "Precision: 0.6540880503144654\n",
      "Recall: 0.9719626168224299\n",
      "F-measure: 0.7819548872180451\n",
      "Model: SVM\n",
      "==================================================\n",
      "Accuracy: 0.6524390243902439\n",
      "Precision: 0.6524390243902439\n",
      "Recall: 1.0\n",
      "F-measure: 0.7896678966789668\n",
      "Model: Logistic Regression\n",
      "==================================================\n",
      "Accuracy: 0.6524390243902439\n",
      "Precision: 0.8289473684210527\n",
      "Recall: 0.5887850467289719\n",
      "F-measure: 0.6885245901639344\n",
      "Model: Random Forest\n",
      "==================================================\n",
      "Accuracy: 0.7682926829268293\n",
      "Precision: 0.7804878048780488\n",
      "Recall: 0.897196261682243\n",
      "F-measure: 0.8347826086956521\n",
      "CPU times: user 18 ms, sys: 1.16 ms, total: 19.2 ms\n",
      "Wall time: 18.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': ['Naïve Bayes', 'SVM', 'Logistic Regression', 'Random Forest'],\n",
       " 'Accuracy': [0.6463414634146342,\n",
       "  0.6524390243902439,\n",
       "  0.6524390243902439,\n",
       "  0.7682926829268293],\n",
       " 'Precision': [0.6540880503144654,\n",
       "  0.6524390243902439,\n",
       "  0.8289473684210527,\n",
       "  0.7804878048780488],\n",
       " 'Recall': [0.9719626168224299, 1.0, 0.5887850467289719, 0.897196261682243],\n",
       " 'F1 Score': [0.7819548872180451,\n",
       "  0.7896678966789668,\n",
       "  0.6885245901639344,\n",
       "  0.8347826086956521]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "result = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": [],\n",
    "}\n",
    "\n",
    "for model_name in best_estimators:\n",
    "    model = best_estimators[model_name]\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    result[\"Model\"].append(model_name)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F-measure:\", f_measure)\n",
    "\n",
    "    result[\"Accuracy\"].append(accuracy)\n",
    "    result[\"Precision\"].append(precision)\n",
    "    result[\"Recall\"].append(recall)\n",
    "    result[\"F1 Score\"].append(f_measure)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feddcf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.781955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.688525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.834783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0          Naïve Bayes  0.646341   0.654088  0.971963  0.781955\n",
       "1                  SVM  0.652439   0.652439  1.000000  0.789668\n",
       "2  Logistic Regression  0.652439   0.828947  0.588785  0.688525\n",
       "3        Random Forest  0.768293   0.780488  0.897196  0.834783"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "perf_ds = Dataset.from_dict(result).to_pandas()\n",
    "perf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b786691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>64.634146</td>\n",
       "      <td>65.408805</td>\n",
       "      <td>97.196262</td>\n",
       "      <td>78.195489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>65.243902</td>\n",
       "      <td>65.243902</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>78.966790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>65.243902</td>\n",
       "      <td>82.894737</td>\n",
       "      <td>58.878505</td>\n",
       "      <td>68.852459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>76.829268</td>\n",
       "      <td>78.048780</td>\n",
       "      <td>89.719626</td>\n",
       "      <td>83.478261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy  Precision      Recall   F1 Score\n",
       "Model                                                           \n",
       "Naïve Bayes          64.634146  65.408805   97.196262  78.195489\n",
       "SVM                  65.243902  65.243902  100.000000  78.966790\n",
       "Logistic Regression  65.243902  82.894737   58.878505  68.852459\n",
       "Random Forest        76.829268  78.048780   89.719626  83.478261"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = perf_ds.set_index(perf_ds.columns[0]).mul(100)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f70337b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>64.6%</td>\n",
       "      <td>65.4%</td>\n",
       "      <td>97.2%</td>\n",
       "      <td>78.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>65.2%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>79.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>65.2%</td>\n",
       "      <td>82.9%</td>\n",
       "      <td>58.9%</td>\n",
       "      <td>68.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>76.8%</td>\n",
       "      <td>78.0%</td>\n",
       "      <td>89.7%</td>\n",
       "      <td>83.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy Precision  Recall F1 Score\n",
       "Model                                                  \n",
       "Naïve Bayes            64.6%     65.4%   97.2%    78.2%\n",
       "SVM                    65.2%     65.2%  100.0%    79.0%\n",
       "Logistic Regression    65.2%     82.9%   58.9%    68.9%\n",
       "Random Forest          76.8%     78.0%   89.7%    83.5%"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in res2.select_dtypes(include=[\"number\"]).columns:\n",
    "    res2[key] = res2[key].apply(\"{:.1f}%\".format)\n",
    "\n",
    "res2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
